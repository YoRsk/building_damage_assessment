{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## TEST :MODEL FCN",
   "id": "891c51ab721a5154"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "initial_id"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 从pytorch提取模型（FCN），并改为自己的backbone",
   "id": "340128a18004bc37"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet50\n",
    "from torchvision.models.segmentation import FCN\n",
    "\n",
    "# Assuming you have a pretrained ResNet model\n",
    "pretrained_resnet = resnet50(pretrained=False)  # Set to False since you'll load your weights\n",
    "pretrained_resnet.load_state_dict(torch.load(\"path_to_your_pretrained_resnet.pth\"))\n",
    "\n",
    "# Create a class to replace the backbone of FCN\n",
    "class MyFCN(nn.Module):\n",
    "    def __init__(self, pretrained_resnet, num_classes):\n",
    "        super(MyFCN, self).__init__()\n",
    "        self.backbone = nn.Sequential(*list(pretrained_resnet.children())[:-2])  # Using your pretrained ResNet's layers\n",
    "        self.classifier = FCN(self.backbone, num_classes=num_classes)  # FCN uses the custom backbone\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(x)\n",
    "\n",
    "# Now create the FCN model with your custom backbone\n",
    "model = MyFCN(pretrained_resnet, num_classes=8).to(DEVICE)\n",
    "\n",
    "# Define your loss function and optimizer\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "adam = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# Training loop remains the same\n",
    "for i in range(EPOCH):\n",
    "    train_history = model_train(train_dataloader, model, ce_loss, adam, i+1)\n",
    "    val_result = model_predict(val_dataloader, model, ce_loss, silent=False)\n",
    "\n",
    "    history = add_history(history, train_history, val_result)\n",
    "\n",
    "print_history(history)\n"
   ],
   "id": "bdedb2b62a001197"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## plt读取mask",
   "id": "b661e376eef99261"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize\n",
    "    ])\n"
   ],
   "id": "8fd0548dd1ae1e40"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# in tensorboard see the architecture of model \n",
    "# vit对输入图像大小有严格要求，需要是32的倍数，所以这里使用256*256的图像\n",
    "from torchvision.models import resnet50\n",
    "#tensorboard\n",
    "#命令行输入 tensorboard --logdir=./training/runs\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('./runs')\n",
    "model = SiameseUNetWithResnet50Encoder()\n",
    "\n",
    "# 定义输入张量，假设输入为两张 256x256 的 RGB 图像\n",
    "input_1 = torch.rand(1, 3, 256, 256)\n",
    "input_2 = torch.rand(1, 3, 256, 256)\n",
    "# 不加torch.no_grad()会报错\n",
    "with torch.no_grad():\n",
    "    writer.add_graph(model, (input_1, input_2))\n",
    "# with torch.no_grad():\n",
    "#     writer.add_graph(model, input_to_model = torch.rand(1, 3, 256, 256))\n",
    "writer.close()"
   ],
   "id": "e37f6328c98bac6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
