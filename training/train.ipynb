{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-03T07:55:55.729008Z",
     "start_time": "2024-09-03T07:55:55.695584Z"
    }
   },
   "source": [
    "from model.my_models import SiameseUNetWithResnet50Encoder\n",
    "from model.evaluate import evaluate\n",
    "from utils.data_loading import SatelliteDataset\n",
    "from utils.dice_score import dice_loss\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.losses.focal import FocalLoss\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from torchvision import transforms\n",
    "from torchmetrics import ConfusionMatrix\n",
    "from torch import optim\n",
    "\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T06:18:50.178067Z",
     "start_time": "2024-09-03T06:18:38.249088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# in tensorboard see the architecture of model \n",
    "# vit对输入图像大小有严格要求，需要是32的倍数，所以这里使用256*256的图像\n",
    "from torchvision.models import resnet50\n",
    "#tensorboard\n",
    "#命令行输入 tensorboard --logdir=./training/runs\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('./runs')\n",
    "model = SiameseUNetWithResnet50Encoder()\n",
    "\n",
    "# 定义输入张量，假设输入为两张 256x256 的 RGB 图像\n",
    "input_1 = torch.rand(1, 3, 256, 256)\n",
    "input_2 = torch.rand(1, 3, 256, 256)\n",
    "# 不加torch.no_grad()会报错\n",
    "with torch.no_grad():\n",
    "    writer.add_graph(model, (input_1, input_2))\n",
    "# with torch.no_grad():\n",
    "#     writer.add_graph(model, input_to_model = torch.rand(1, 3, 256, 256))\n",
    "writer.close()"
   ],
   "id": "a7086be02cebd151",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liuyi\\segment\\damage-assessment\\model\\my_functions.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if(diffY<0):\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T07:55:58.379287Z",
     "start_time": "2024-09-03T07:55:58.371569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img_home_path = \"C:/Users/liuyi/segment/ubdd/xbd\"\n",
    "post_dir_img = img_home_path + \"/Dataset/TierFull/Post/Image512/\"\n",
    "post_dir_mask = img_home_path + \"/Dataset/TierFull/Post/Label512/\"\n",
    "pre_dir_img = img_home_path + \"/Dataset/TierFull/Pre/Image512/\"\n",
    "pre_dir_mask = img_home_path + \"/Dataset/TierFull/Pre/Label512/\"\n",
    "post_dir_val_img = img_home_path + \"/Dataset/Validation/Post/Image512/\"\n",
    "post_dir_val_mask = img_home_path + \"/Dataset/Validation/Post/Label512/\"\n",
    "pre_dir_val_img = img_home_path + \"/Dataset/Validation/Pre/Image512/\"\n",
    "pre_dir_val_mask = img_home_path + \"/Dataset/Validation/Pre/Label512/\"\n",
    "# post_dir_img = Path('.\\\\Dataset\\\\TierFull\\\\Post\\\\Image512\\\\')\n",
    "# post_dir_mask = Path('.\\\\Dataset\\\\TierFull\\\\Post\\\\Label512\\\\')\n",
    "# pre_dir_img = Path('.\\\\Dataset\\\\TierFull\\\\Pre\\\\Image512\\\\')\n",
    "# pre_dir_mask = Path('.\\\\Dataset\\\\TierFull\\\\Pre\\\\Label512\\\\')\n",
    "# post_dir_val_img = Path('.\\\\Dataset\\\\Validation\\\\Post\\\\Image512\\\\')\n",
    "# post_dir_val_mask = Path('.\\\\Dataset\\\\Validation\\\\Post\\\\Label512\\\\')\n",
    "# pre_dir_val_img = Path('.\\\\Dataset\\\\Validation\\\\Pre\\\\Image512\\\\')\n",
    "# pre_dir_val_mask = Path('.\\\\Dataset\\\\Validation\\\\Pre\\\\Label512\\\\')\n",
    "dir_checkpoint = Path('./checkpoints/Vgg19SiamConc/')"
   ],
   "id": "facb3659ae0b68",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T07:56:01.668295Z",
     "start_time": "2024-09-03T07:56:01.660349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "closs = nn.CrossEntropyLoss()\n",
    "\n",
    "floss = FocalLoss(mode = 'multiclass',\n",
    "                alpha = None,\n",
    "                gamma = 2.0,\n",
    "                ignore_index = None,\n",
    "                reduction = \"mean\",\n",
    "                normalized = False,\n",
    "                reduced_threshold = None)"
   ],
   "id": "a1606a6cbf45f917",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T07:33:55.761169Z",
     "start_time": "2024-09-03T07:23:17.902377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#TODO:mask_suffix = '.png')是干啊的，在原文档的上一个版本的commit中能找到 ,increase = 8397\n",
    "def get_class_weights():\n",
    "    train = SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, 1, values =  [[1,1], True, True, True], probabilities = [.5,.5,.5,0,0,0,0])\n",
    "    # 设置DataLoader\n",
    "    loader_args = dict(batch_size=1, num_workers=1, pin_memory=True)        \n",
    "    train_loader = DataLoader(train, shuffle=True, **loader_args)\n",
    "     # 用于统计每个类别的频次，假设有5个类别\n",
    "    classes = torch.zeros(5)\n",
    "    with tqdm(total=len(train_loader), unit='img') as pbar:\n",
    "        for batch in train_loader:\n",
    "            image = batch['premask'].int() # 获取mask\n",
    "            count = torch.bincount(torch.flatten(image),minlength = 5)\n",
    "            classes = classes.add(count)\n",
    "            pbar.update(image.shape[0])\n",
    "    return torch.div(classes,torch.sum(classes))\n",
    "print(get_class_weights())"
   ],
   "id": "c5bd79b74dcc1a11",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2800/2800 [10:37<00:00,  4.39img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9382, 0.0618, 0.0000, 0.0000, 0.0000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T07:56:05.368309Z",
     "start_time": "2024-09-03T07:56:05.327122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_net(net,\n",
    "              device,\n",
    "              start_epoch: int = 1,\n",
    "              epochs: int = 5,\n",
    "              batch_size: int = 1,\n",
    "              learning_rate: float = 1e-5,\n",
    "              train_percent: float = 0.5,\n",
    "              val_percent: float = 0.1,\n",
    "              save_checkpoint: bool = True,\n",
    "              img_scale: float = 0.5,\n",
    "              ampbool: bool = False,\n",
    "              traintype: str = 'post',\n",
    "              gradient_clipping: float = 1.0):\n",
    "    # 1. Create dataset\n",
    "    train = None\n",
    "    validate = None\n",
    "\n",
    "    try:\n",
    "        train = SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, 1, values =  [[.8,1.5], True, True,True], probabilities = [0,0,0,0])\n",
    "        # train = SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, 1, values =  [[.8,1.5], True, True,True], probabilities = [0,0,0,0],increase = 0 ,mask_suffix = '.png',normalizemodel = 'vgg19')\n",
    "        validate = SatelliteDataset(pre_dir_val_img, pre_dir_val_mask,post_dir_val_img, post_dir_val_mask, 1, values =  [[1,1], False, False, False], probabilities = [0,0,0,0])\n",
    "    except (AssertionError, RuntimeError):\n",
    "        print('error')\n",
    "\n",
    "    loader_args = dict(batch_size=1, num_workers=1, pin_memory=True)        \n",
    "        \n",
    "    # 2. Split into train / validation partitions\n",
    "    n_train = int(len(train) * train_percent)\n",
    "    n_train_none = int(len(train) - n_train)\n",
    "    n_val = int(len(validate) * val_percent)\n",
    "    n_val_none = int(len(validate) - n_val)\n",
    "\n",
    "    train_set, train_val_none_set = random_split(train, [n_train, n_train_none], generator=torch.Generator().manual_seed(0))\n",
    "    \n",
    "    train_loader = DataLoader(train_set, shuffle=True, **loader_args)    \n",
    "\n",
    "    val_set, val_none_set = random_split(validate, [n_val, n_val_none], generator=torch.Generator().manual_seed(0))    \n",
    "\n",
    "    val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)    \n",
    "\n",
    "    # 4. Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n",
    "    optimizer = optim.RMSprop(net.parameters(), lr=learning_rate, weight_decay=1e-6, momentum=0.9, foreach=True)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[3,6,9,12,15,18,19,20, 33, 47, 50, 60, 70, 90, 110, 130, 150, 170, 180, 190], gamma=0.5)\n",
    "    grad_scaler = torch.cuda.amp.GradScaler(enabled=ampbool)\n",
    "    criterion = closs\n",
    "    global_step = 0\n",
    "\n",
    "    # 5. Begin training\n",
    "    for epoch in range(start_epoch, start_epoch + epochs):\n",
    "        net.train()\n",
    "        epoch_loss = 0\n",
    "        nancount = 0\n",
    "        with tqdm(total=n_train, desc=f'Epoch {epoch}/{epochs}', unit='img') as pbar:\n",
    "            for batch in train_loader:\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                preimage, postimage, post_masks, pre_masks = batch['preimage'], batch['postimage'], batch['postmask'], batch['premask']\n",
    "\n",
    "                preimage = preimage.to(device=device, dtype=torch.float32)\n",
    "                postimage = postimage.to(device=device, dtype=torch.float32)\n",
    "                post_masks = post_masks.to(device=device, dtype=torch.long)\n",
    "                pre_masks = pre_masks.to(device=device, dtype=torch.long)\n",
    "                with torch.cuda.amp.autocast(enabled = ampbool):\n",
    "                    masks_pred = None\n",
    "                    if(traintype == 'both'):\n",
    "                        masks_pred = net(preimage,postimage)\n",
    "                        loss = criterion(masks_pred, post_masks)\n",
    "                        loss += dice_loss(\n",
    "                            F.softmax(masks_pred, dim=1).float()[:, 1:, ...],\n",
    "                            F.one_hot(post_masks, 5).permute(0, 3, 1, 2).float()[:, 1:, ...],\n",
    "                            multiclass=True\n",
    "                        )\n",
    "                    if(traintype == 'pre'):\n",
    "                        masks_pred = net(preimage)\n",
    "                        loss = criterion(masks_pred, pre_masks)\n",
    "                        loss += dice_loss(\n",
    "                            F.softmax(masks_pred, dim=1).float(),\n",
    "                            F.one_hot(pre_masks, 2).permute(0, 3, 1, 2).float(),\n",
    "                            multiclass=True\n",
    "                        )\n",
    "                    if(traintype == 'post'):\n",
    "                        masks_pred = net(postimage)\n",
    "                        loss = criterion(masks_pred, post_masks)\n",
    "                        loss += dice_loss(\n",
    "                            F.softmax(masks_pred, dim=1).float()[:, 1:, ...],\n",
    "                            F.one_hot(post_masks, 5).permute(0, 3, 1, 2).float()[:, 1:, ...],\n",
    "                            multiclass=True\n",
    "                        )\n",
    "                    \n",
    "                grad_scaler.scale(loss).backward()\n",
    "                #torch.nn.utils.clip_grad_norm_(net.parameters(), gradient_clipping)\n",
    "                grad_scaler.step(optimizer)\n",
    "                grad_scaler.update()\n",
    "                pbar.update(postimage.shape[0])\n",
    "                global_step += 1\n",
    "                if(math.isnan(loss.item())):\n",
    "                    epoch_loss+=0\n",
    "                    nancount +=1\n",
    "                else:\n",
    "                    epoch_loss += loss.item()\n",
    "                pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "                        \n",
    "        val_score, val_classes,val_loss = evaluate(net,dataloader = val_loader,device = device,ampbool = ampbool,traintype = traintype)\n",
    "        scheduler.step(val_score)\n",
    "        print(val_score)\n",
    "        print(val_classes)\n",
    "        print(val_loss)\n",
    "        print(epoch_loss/n_train)\n",
    "        print(nancount)\n",
    "        if save_checkpoint:\n",
    "            Path(dir_checkpoint).mkdir(parents=True, exist_ok=True)\n",
    "            torch.save(net.state_dict(), str(dir_checkpoint / 'branch12checkpoint_epoch_branch_{}.pth'.format(epoch)))\n",
    "            logging.info(f'Checkpoint {epoch} saved!')"
   ],
   "id": "cf171a33a2c07a5a",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T07:58:01.675332Z",
     "start_time": "2024-09-03T07:58:01.667626Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classes = 5\n",
    "bilinear = True\n",
    "loadstate = False\n",
    "# loadstate = True\n",
    "load = './checkpoints/Vgg19SiamConc/checkpoint_epoch12.pth'\n",
    "start_epoch = 13\n",
    "epochs = 20\n",
    "batch_size = 1\n",
    "lr = 1e-6\n",
    "scale = 1\n",
    "train =0.15259598603*2\n",
    "val = 1\n",
    "ampbool = True\n",
    "save_checkpoint = True\n",
    "traintype = 'both'\n",
    "gradclip = 1.0"
   ],
   "id": "abbc24f28ad0b659",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T07:58:03.723754Z",
     "start_time": "2024-09-03T07:58:03.718600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def confusionmatrix(pred,true):\n",
    "    result = np.zeros((5,5))\n",
    "    for i in range(true.shape[1]):\n",
    "        for j in range(true.shape[2]):\n",
    "            result[true[0][i][j]][pred[0][i][j]] +=1\n",
    "    return result"
   ],
   "id": "7e9ed12de022451e",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T13:34:03.079391Z",
     "start_time": "2024-09-03T13:34:03.035146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def modelconfusionmatrix(filepath,net,train_percent,val_percent):\n",
    "    device = 'cuda'\n",
    "    net.load_state_dict(torch.load(filepath, map_location=device))\n",
    "    net.to(device=device)\n",
    "    net.eval() # 评估模式\n",
    "    \n",
    "    # 新增的\n",
    "    train = None\n",
    "    validate = None\n",
    "    \n",
    "    try:\n",
    "        train = SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, 1, values =  [[.8,1.5], True, True,True], probabilities = [0,0,0,0])\n",
    "        validate = SatelliteDataset(pre_dir_val_img, pre_dir_val_mask,post_dir_val_img, post_dir_val_mask, 1, values =  [[1,1], False, False, False], probabilities = [0,0,0,0])\n",
    "        # train = SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, 1, values =  [[.8,1.5], True, True,True], probabilities = [0,0,0,0],increase = 0 ,mask_suffix = '.png',normalizemodel = 'vgg19')\n",
    "        # validate = SatelliteDataset(pre_dir_val_img, pre_dir_val_mask,post_dir_val_img, post_dir_val_mask, 1, values =  [[1,1], False, False, False], probabilities = [0,0,0,0],increase = 0,mask_suffix = '.png', normalizemodel = 'vgg19')\n",
    "    except (AssertionError, RuntimeError):\n",
    "        print('error')\n",
    "\n",
    "    loader_args = dict(batch_size=1, num_workers=1, pin_memory=True)        \n",
    "        \n",
    "    # 2. Split into train / validation partitions\n",
    "    n_train = int(len(train) * train_percent)\n",
    "    n_train_none = int(len(train) - n_train)\n",
    "    n_val = int(len(validate) * val_percent)\n",
    "    n_val_none = int(len(validate) - n_val)\n",
    "\n",
    "    train_set, train_val_none_set = random_split(train, [n_train, n_train_none], generator=torch.Generator().manual_seed(0))\n",
    "    \n",
    "    train_loader = DataLoader(train_set, shuffle=True, **loader_args)    \n",
    "\n",
    "    val_set, val_none_set = random_split(validate, [n_val, n_val_none], generator=torch.Generator().manual_seed(0))    \n",
    "\n",
    "    val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args) \n",
    "    resulttrain = torch.zeros(5,5).to(device)\n",
    "    resultval = torch.zeros(5,5).to(device)\n",
    "\n",
    "    num_val_batches = len(val_loader)\n",
    "    num_train_batches = len(train_loader)\n",
    "    confmat = ConfusionMatrix(task=\"multiclass\", num_classes=5).to(device)\n",
    "\n",
    "    with tqdm(total=num_train_batches, desc='train', unit='img') as pbar:\n",
    "        for batch in train_loader:\n",
    "            preimage, postimage, true_masks = batch['preimage'], batch['postimage'], batch['postmask']\n",
    "            # preimage, postimage, true_masks = batch['preimage'], batch['image'], batch['mask']\n",
    "            preimage = preimage.to(device=device, dtype=torch.float32)\n",
    "            postimage = postimage.to(device=device, dtype=torch.float32)\n",
    "            true_masks = true_masks.to(device=device, dtype=torch.long)\n",
    "            mask_true = F.one_hot(true_masks, 5).permute(0,3, 1, 2).float()\n",
    "            with torch.cuda.amp.autocast(enabled = True):\n",
    "                # predict the mask\n",
    "                mask_pred = net(preimage,postimage)\n",
    "                # convert to one-hot format\n",
    "                pred = F.softmax(mask_pred, dim=1).int().argmax(-3)\n",
    "                true = F.one_hot(true_masks, 5).int().permute(0, 3, 1, 2).argmax(-3)\n",
    "                resulttrain += confmat(pred,true)\n",
    "            pbar.update(postimage.shape[0])\n",
    "    print(resulttrain)\n",
    "    with tqdm(total=num_val_batches, desc='validation', unit='img') as pbar:\n",
    "        for batch in val_loader:\n",
    "            preimage, postimage, true_masks = batch['preimage'], batch['image'], batch['mask']\n",
    "            preimage = preimage.to(device=device, dtype=torch.float32)\n",
    "            postimage = postimage.to(device=device, dtype=torch.float32)\n",
    "            true_masks = true_masks.to(device=device, dtype=torch.long)\n",
    "            mask_true = F.one_hot(true_masks, 5).permute(0,3, 1, 2).float()\n",
    "            with torch.cuda.amp.autocast(enabled = True):\n",
    "                # predict the mask\n",
    "                mask_pred = net(preimage,postimage)\n",
    "                # convert to one-hot format\n",
    "                pred = F.softmax(mask_pred, dim=1).int().argmax(-3)\n",
    "                true = F.one_hot(true_masks, 5).int().permute(0, 3, 1, 2).argmax(-3)\n",
    "                resultval += confmat(pred,true)\n",
    "            pbar.update(postimage.shape[0])\n",
    "    print(resultval)\n",
    "    net.train()\n",
    "\n",
    "    # Fixes a potential division by zero error\n",
    "    if num_val_batches == 0:\n",
    "        return resulttrain,resultval\n",
    "    return resulttrain,resultval"
   ],
   "id": "b948416bc246378b",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T13:42:55.339046Z",
     "start_time": "2024-09-03T13:42:55.306962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def EvaluateFolder(folderpath,net,train_percent,val_percent):\n",
    "    in_files = [folderpath + s for s in os.listdir(folderpath)]\n",
    "    try:\n",
    "        train = SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, 1, values =  [[.8,1.5], True, True,True], probabilities = [0,0,0,0])\n",
    "        # train = SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, 1, values =  [[.8,1.5], True, True,True], probabilities = [0,0,0,0],increase = 0 ,mask_suffix = '.png',normalizemodel = 'vgg19')\n",
    "        validate = SatelliteDataset(pre_dir_val_img, pre_dir_val_mask,post_dir_val_img, post_dir_val_mask, 1, values =  [[1,1], False, False, False], probabilities = [0,0,0,0]) \n",
    "        # validate = SatelliteDataset(pre_dir_val_img, pre_dir_val_mask,post_dir_val_img, post_dir_val_mask, 1, values =  [[1,1], False, False, False], probabilities = [0,0,0,0],increase = 0,mask_suffix = '.png', normalizemodel = 'vgg19')\n",
    "    except (AssertionError, RuntimeError):\n",
    "        print('error')\n",
    "\n",
    "    loader_args = dict(batch_size=1, num_workers=1, pin_memory=True)        \n",
    "        \n",
    "    # 2. Split into train / validation partitions\n",
    "    n_train = int(len(train) * train_percent)\n",
    "    n_train_none = int(len(train) - n_train)\n",
    "    n_val = int(len(validate) * val_percent)\n",
    "    n_val_none = int(len(validate) - n_val)\n",
    "\n",
    "    train_set, train_val_none_set = random_split(train, [n_train, n_train_none], generator=torch.Generator().manual_seed(0))\n",
    "    \n",
    "    train_loader = DataLoader(train_set, shuffle=True, **loader_args)    \n",
    "\n",
    "    val_set, val_none_set = random_split(validate, [n_val, n_val_none], generator=torch.Generator().manual_seed(0))    \n",
    "\n",
    "    val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    loader_args = dict(batch_size=1, num_workers=1, pin_memory=True)        \n",
    "    \n",
    "    for i in in_files:\n",
    "        net.load_state_dict(torch.load(i, map_location=device))\n",
    "        net.to(device=device)\n",
    "        val_score, val_classes,val_loss = evaluate(net,dataloader = val_loader,device = device,ampbool = True,traintype = 'both')\n",
    "        train_score, train_classes,train_loss = evaluate(net,dataloader = train_loader,device = device,ampbool = True,traintype = 'both')\n",
    "        print('Train: ' + i)\n",
    "        print(train_score)\n",
    "        print(train_classes)\n",
    "        print(train_loss)\n",
    "        print('Validation: ' + i)\n",
    "        print(val_score)\n",
    "        print(val_classes)\n",
    "        print(val_loss)"
   ],
   "id": "68343e76dce750c1",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T13:57:55.953485Z",
     "start_time": "2024-09-03T13:57:53.137371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# net = SiamUNetConCVgg19()\n",
    "net = SiameseUNetWithResnet50Encoder()"
   ],
   "id": "96d2349ef657b1a4",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T13:43:40.540946Z",
     "start_time": "2024-09-03T13:43:40.456026Z"
    }
   },
   "cell_type": "code",
   "source": "EvaluateFolder('./checkpoints/Final/',net,train,val)",
   "id": "6693f5575c23882e",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: './checkpoints/Final/'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[22], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m EvaluateFolder(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./checkpoints/Final/\u001B[39m\u001B[38;5;124m'\u001B[39m,net,train,val)\n",
      "Cell \u001B[1;32mIn[19], line 2\u001B[0m, in \u001B[0;36mEvaluateFolder\u001B[1;34m(folderpath, net, train_percent, val_percent)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mEvaluateFolder\u001B[39m(folderpath,net,train_percent,val_percent):\n\u001B[1;32m----> 2\u001B[0m     in_files \u001B[38;5;241m=\u001B[39m [folderpath \u001B[38;5;241m+\u001B[39m s \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m os\u001B[38;5;241m.\u001B[39mlistdir(folderpath)]\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m      4\u001B[0m         train \u001B[38;5;241m=\u001B[39m SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, \u001B[38;5;241m1\u001B[39m, values \u001B[38;5;241m=\u001B[39m  [[\u001B[38;5;241m.8\u001B[39m,\u001B[38;5;241m1.5\u001B[39m], \u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;28;01mTrue\u001B[39;00m,\u001B[38;5;28;01mTrue\u001B[39;00m], probabilities \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m0\u001B[39m])\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 3] 系统找不到指定的路径。: './checkpoints/Final/'"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T13:43:56.037242Z",
     "start_time": "2024-09-03T13:43:56.016085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])"
   ],
   "id": "65f38a4fc06055b2",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T13:43:57.358257Z",
     "start_time": "2024-09-03T13:43:57.326253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mem_params = sum([param.nelement()*param.element_size() for param in net.parameters()])\n",
    "mem_bufs = sum([buf.nelement()*buf.element_size() for buf in net.buffers()])\n",
    "mem = mem_params + mem_bufs\n",
    "mem"
   ],
   "id": "cc9435c0dde00a3f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "548496724"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-09-03T13:57:59.804331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "    #net = SiamUNetDiff()\n",
    "    #net = SiamUNetConC()\n",
    "    #net = SiameseUNetWithResnet50Encoder()\n",
    "    #net = SiamUnet_diff_Full(3,5)\n",
    "    #net = UNetWithResnet50Encoder(5,'custom','./checkpoints/Resnet50ContrastiveWeight/checkpoint_epoch0.pth')\n",
    "    #net = UNet(out_classes=classes, up_sample_mode='conv_transpose',batch_norm=False)\n",
    "    #net = SiameseUNet(n_channels=3, n_classes = classes, bilinear=bilinear)\n",
    "    #net = UNetVgg19V2(out_classes=classes, up_sample_mode='conv_transpose')\n",
    "    #net = vgg19bn_unet(5,True)\n",
    "    #net = vgg19nobn_unet(5,True)\n",
    "    #net = vgg19nobn_unetdouble(5,True)\n",
    "    #net = VGGUnet19nobnspace(out_channels = 5, pretrained = True)\n",
    "    #net = SiamUNetCombVgg19()\n",
    "    ### 之前是用这个 net = SiamUNetConCVgg19()\n",
    "    #net = resnet_unet()\n",
    "    #net = VGG16Unet(out_channels = 5)\n",
    "    #net = resnet_siamunet()\n",
    "    #net = SiamUNetDiffVgg19()\n",
    "    #net = SiamUNetFullConCVgg19()\n",
    "    #net = SiamUNetConCResnet50(True,5)\n",
    "    #net = UNETResnet50(True,2)\n",
    "    '''net = smp.Unet(\n",
    "        encoder_name='resnext101_32x8d',\n",
    "        encoder_depth=5,\n",
    "        encoder_weights='imagenet',\n",
    "        decoder_use_batchnorm=False,\n",
    "        decoder_channels=(1024,512,256,128, 64),\n",
    "        decoder_attention_type=None,\n",
    "        in_channels=3,\n",
    "        classes=5,\n",
    "        activation=None,\n",
    "        aux_params=None\n",
    "    )\n",
    "    '''\n",
    "    if loadstate:\n",
    "        net.load_state_dict(torch.load(load, map_location=device))\n",
    "        logging.info(f'Model loaded from {load}')\n",
    "\n",
    "    net.to(device=device)\n",
    "    train_net(net=net,\n",
    "                  start_epoch = start_epoch,\n",
    "                  epochs=epochs,\n",
    "                  batch_size=batch_size,\n",
    "                  learning_rate=lr,\n",
    "                  device=device,\n",
    "                  img_scale=scale,\n",
    "                  train_percent = train,\n",
    "                  val_percent=val,\n",
    "                  save_checkpoint = save_checkpoint,\n",
    "                  ampbool = ampbool,\n",
    "                  traintype = traintype,\n",
    "                  gradient_clipping=gradclip)"
   ],
   "id": "a1fb80075cdc127b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liuyi\\AppData\\Local\\Temp\\ipykernel_47644\\3917023748.py:44: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  grad_scaler = torch.cuda.amp.GradScaler(enabled=ampbool)\n",
      "Epoch 13/20:   0%|          | 0/854 [00:00<?, ?img/s]C:\\Users\\liuyi\\AppData\\Local\\Temp\\ipykernel_47644\\3917023748.py:62: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled = ampbool):\n",
      "Epoch 13/20:   0%|          | 2/854 [00:59<6:38:42, 28.08s/img, loss (batch)=2.75]"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
