{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-03T14:31:16.059879Z",
     "start_time": "2024-09-03T14:31:16.030493Z"
    }
   },
   "source": [
    "from model.my_models import SiameseUNetWithResnet50Encoder\n",
    "from model.evaluate import evaluate\n",
    "from utils.data_loading import SatelliteDataset\n",
    "from utils.dice_score import dice_loss\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.losses.focal import FocalLoss\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from torchvision import transforms\n",
    "from torchmetrics import ConfusionMatrix\n",
    "from torch import optim\n",
    "\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T06:18:50.178067Z",
     "start_time": "2024-09-03T06:18:38.249088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# in tensorboard see the architecture of model \n",
    "# vit对输入图像大小有严格要求，需要是32的倍数，所以这里使用256*256的图像\n",
    "from torchvision.models import resnet50\n",
    "#tensorboard\n",
    "#命令行输入 tensorboard --logdir=./training/runs\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('./runs')\n",
    "model = SiameseUNetWithResnet50Encoder()\n",
    "\n",
    "# 定义输入张量，假设输入为两张 256x256 的 RGB 图像\n",
    "input_1 = torch.rand(1, 3, 256, 256)\n",
    "input_2 = torch.rand(1, 3, 256, 256)\n",
    "# 不加torch.no_grad()会报错\n",
    "with torch.no_grad():\n",
    "    writer.add_graph(model, (input_1, input_2))\n",
    "# with torch.no_grad():\n",
    "#     writer.add_graph(model, input_to_model = torch.rand(1, 3, 256, 256))\n",
    "writer.close()"
   ],
   "id": "a7086be02cebd151",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liuyi\\segment\\damage-assessment\\model\\my_functions.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if(diffY<0):\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T14:31:20.528970Z",
     "start_time": "2024-09-03T14:31:20.517734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img_home_path = \"C:/Users/liuyi/segment/ubdd/xbd\"\n",
    "post_dir_img = img_home_path + \"/Dataset/TierFull/Post/Image512/\"\n",
    "post_dir_mask = img_home_path + \"/Dataset/TierFull/Post/Label512/\"\n",
    "pre_dir_img = img_home_path + \"/Dataset/TierFull/Pre/Image512/\"\n",
    "pre_dir_mask = img_home_path + \"/Dataset/TierFull/Pre/Label512/\"\n",
    "post_dir_val_img = img_home_path + \"/Dataset/Validation/Post/Image512/\"\n",
    "post_dir_val_mask = img_home_path + \"/Dataset/Validation/Post/Label512/\"\n",
    "pre_dir_val_img = img_home_path + \"/Dataset/Validation/Pre/Image512/\"\n",
    "pre_dir_val_mask = img_home_path + \"/Dataset/Validation/Pre/Label512/\"\n",
    "# post_dir_img = Path('.\\\\Dataset\\\\TierFull\\\\Post\\\\Image512\\\\')\n",
    "# post_dir_mask = Path('.\\\\Dataset\\\\TierFull\\\\Post\\\\Label512\\\\')\n",
    "# pre_dir_img = Path('.\\\\Dataset\\\\TierFull\\\\Pre\\\\Image512\\\\')\n",
    "# pre_dir_mask = Path('.\\\\Dataset\\\\TierFull\\\\Pre\\\\Label512\\\\')\n",
    "# post_dir_val_img = Path('.\\\\Dataset\\\\Validation\\\\Post\\\\Image512\\\\')\n",
    "# post_dir_val_mask = Path('.\\\\Dataset\\\\Validation\\\\Post\\\\Label512\\\\')\n",
    "# pre_dir_val_img = Path('.\\\\Dataset\\\\Validation\\\\Pre\\\\Image512\\\\')\n",
    "# pre_dir_val_mask = Path('.\\\\Dataset\\\\Validation\\\\Pre\\\\Label512\\\\')\n",
    "dir_checkpoint = Path('./checkpoints/Vgg19SiamConc/')"
   ],
   "id": "facb3659ae0b68",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T14:31:22.143927Z",
     "start_time": "2024-09-03T14:31:22.134357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "closs = nn.CrossEntropyLoss()\n",
    "\n",
    "floss = FocalLoss(mode = 'multiclass',\n",
    "                alpha = None,\n",
    "                gamma = 2.0,\n",
    "                ignore_index = None,\n",
    "                reduction = \"mean\",\n",
    "                normalized = False,\n",
    "                reduced_threshold = None)"
   ],
   "id": "a1606a6cbf45f917",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T14:31:26.286688Z",
     "start_time": "2024-09-03T14:31:23.756686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#TODO:mask_suffix = '.png')是干啊的，在原文档的上一个版本的commit中能找到 ,increase = 8397\n",
    "def get_class_weights():\n",
    "    train = SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, 1, values =  [[1,1], True, True, True], probabilities = [.5,.5,.5,0,0,0,0])\n",
    "    # 设置DataLoader\n",
    "    loader_args = dict(batch_size=1, num_workers=1, pin_memory=True)        \n",
    "    train_loader = DataLoader(train, shuffle=True, **loader_args)\n",
    "     # 用于统计每个类别的频次，假设有5个类别\n",
    "    classes = torch.zeros(5)\n",
    "    with tqdm(total=len(train_loader), unit='img') as pbar:\n",
    "        for batch in train_loader:\n",
    "            image = batch['premask'].int() # 获取mask\n",
    "            count = torch.bincount(torch.flatten(image),minlength = 5)\n",
    "            classes = classes.add(count)\n",
    "            pbar.update(image.shape[0])\n",
    "    return torch.div(classes,torch.sum(classes))\n",
    "print(get_class_weights())"
   ],
   "id": "c5bd79b74dcc1a11",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2800 [00:05<?, ?img/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 16\u001B[0m\n\u001B[0;32m     14\u001B[0m             pbar\u001B[38;5;241m.\u001B[39mupdate(image\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mdiv(classes,torch\u001B[38;5;241m.\u001B[39msum(classes))\n\u001B[1;32m---> 16\u001B[0m \u001B[38;5;28mprint\u001B[39m(get_class_weights())\n",
      "Cell \u001B[1;32mIn[31], line 10\u001B[0m, in \u001B[0;36mget_class_weights\u001B[1;34m()\u001B[0m\n\u001B[0;32m      8\u001B[0m classes \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;241m5\u001B[39m)\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tqdm(total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(train_loader), unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimg\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m pbar:\n\u001B[1;32m---> 10\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[0;32m     11\u001B[0m         image \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpremask\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mint() \u001B[38;5;66;03m# 获取mask\u001B[39;00m\n\u001B[0;32m     12\u001B[0m         count \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mbincount(torch\u001B[38;5;241m.\u001B[39mflatten(image),minlength \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m5\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\xbdtwostep\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    628\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 630\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_data()\n\u001B[0;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\xbdtwostep\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1327\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1324\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_data(data)\n\u001B[0;32m   1326\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shutdown \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m-> 1327\u001B[0m idx, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_data()\n\u001B[0;32m   1328\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1329\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable:\n\u001B[0;32m   1330\u001B[0m     \u001B[38;5;66;03m# Check for _IterableDatasetStopIteration\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\xbdtwostep\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1283\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._get_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1281\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m   1282\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_thread\u001B[38;5;241m.\u001B[39mis_alive():\n\u001B[1;32m-> 1283\u001B[0m         success, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_try_get_data()\n\u001B[0;32m   1284\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m success:\n\u001B[0;32m   1285\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\xbdtwostep\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1131\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m   1118\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_try_get_data\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m_utils\u001B[38;5;241m.\u001B[39mMP_STATUS_CHECK_INTERVAL):\n\u001B[0;32m   1119\u001B[0m     \u001B[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001B[39;00m\n\u001B[0;32m   1120\u001B[0m     \u001B[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1128\u001B[0m     \u001B[38;5;66;03m# Returns a 2-tuple:\u001B[39;00m\n\u001B[0;32m   1129\u001B[0m     \u001B[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001B[39;00m\n\u001B[0;32m   1130\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1131\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_queue\u001B[38;5;241m.\u001B[39mget(timeout\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[0;32m   1132\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m, data)\n\u001B[0;32m   1133\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1134\u001B[0m         \u001B[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001B[39;00m\n\u001B[0;32m   1135\u001B[0m         \u001B[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001B[39;00m\n\u001B[0;32m   1136\u001B[0m         \u001B[38;5;66;03m# worker failures.\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\xbdtwostep\\Lib\\queue.py:180\u001B[0m, in \u001B[0;36mQueue.get\u001B[1;34m(self, block, timeout)\u001B[0m\n\u001B[0;32m    178\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m remaining \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m:\n\u001B[0;32m    179\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m Empty\n\u001B[1;32m--> 180\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnot_empty\u001B[38;5;241m.\u001B[39mwait(remaining)\n\u001B[0;32m    181\u001B[0m item \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get()\n\u001B[0;32m    182\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnot_full\u001B[38;5;241m.\u001B[39mnotify()\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\xbdtwostep\\Lib\\threading.py:331\u001B[0m, in \u001B[0;36mCondition.wait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    330\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 331\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m waiter\u001B[38;5;241m.\u001B[39macquire(\u001B[38;5;28;01mTrue\u001B[39;00m, timeout)\n\u001B[0;32m    332\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    333\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m waiter\u001B[38;5;241m.\u001B[39macquire(\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T14:58:44.996016Z",
     "start_time": "2024-09-03T14:58:44.874918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import torchmetrics\n",
    "import numpy as np\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train_net(net,\n",
    "              device,\n",
    "              start_epoch: int = 1,\n",
    "              epochs: int = 5,\n",
    "              batch_size: int = 1,\n",
    "              learning_rate: float = 1e-5,\n",
    "              train_percent: float = 0.5,\n",
    "              val_percent: float = 0.1,\n",
    "              save_checkpoint: bool = True,\n",
    "              img_scale: float = 0.5,\n",
    "              ampbool: bool = False,\n",
    "              traintype: str = 'post',\n",
    "              gradient_clipping: float = 1.0):\n",
    "    # 1. Create dataset\n",
    "    train = None\n",
    "    validate = None\n",
    "\n",
    "    try:\n",
    "        train = SatelliteDataset(pre_dir_img, pre_dir_mask, post_dir_img, post_dir_mask, 1, values=[[.8,1.5], True, True, True], probabilities=[0, 0, 0, 0])\n",
    "        validate = SatelliteDataset(pre_dir_val_img, pre_dir_val_mask, post_dir_val_img, post_dir_val_mask, 1, values=[[1, 1], False, False, False], probabilities=[0, 0, 0, 0])\n",
    "    except (AssertionError, RuntimeError):\n",
    "        print('error')\n",
    "\n",
    "    loader_args = dict(batch_size=batch_size, num_workers=1, pin_memory=True)\n",
    "    \n",
    "    # 2. Split into train / validation partitions\n",
    "    n_train = int(len(train) * train_percent)\n",
    "    n_train_none = int(len(train) - n_train)\n",
    "    n_val = int(len(validate) * val_percent)\n",
    "    n_val_none = int(len(validate) - n_val)\n",
    "\n",
    "    train_set, train_val_none_set = random_split(train, [n_train, n_train_none], generator=torch.Generator().manual_seed(0))\n",
    "    train_loader = DataLoader(train_set, shuffle=True, **loader_args)\n",
    "\n",
    "    val_set, val_none_set = random_split(validate, [n_val, n_val_none], generator=torch.Generator().manual_seed(0))\n",
    "    val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)\n",
    "\n",
    "    # 4. Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n",
    "    optimizer = optim.RMSprop(net.parameters(), lr=learning_rate, weight_decay=1e-6, momentum=0.9, foreach=True)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[3,6,9,12,15,18,19,20,33,47,50,60,70,90,110,130,150,170,180,190], gamma=0.5)\n",
    "    grad_scaler = torch.cuda.amp.GradScaler(enabled=ampbool)\n",
    "    criterion = closs\n",
    "    \n",
    "    # Initialize torchmetrics metrics\n",
    "    accuracy = torchmetrics.Accuracy(task='multiclass', num_classes=5, validate_args=False).to(device)\n",
    "    precision = torchmetrics.Precision(task='multiclass', num_classes=5, average='macro', validate_args=False).to(device)\n",
    "    recall = torchmetrics.Recall(task='multiclass', num_classes=5, average='macro', validate_args=False).to(device)\n",
    "\n",
    "    global_step = 0\n",
    "\n",
    "    # 5. Begin training\n",
    "    for epoch in range(start_epoch, start_epoch + epochs):\n",
    "        net.train()\n",
    "        epoch_loss = 0\n",
    "        nancount = 0\n",
    "        \n",
    "        # Initialize metrics accumulators\n",
    "        avg_loss = 0.0\n",
    "        avg_acc = 0.0\n",
    "        avg_prec = 0.0\n",
    "        avg_rec = 0.0\n",
    "        \n",
    "        with tqdm(total=n_train, desc=f'Epoch {epoch}/{epochs}', unit='img') as pbar:\n",
    "            for batch in train_loader:\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                preimage, postimage, post_masks, pre_masks = batch['preimage'], batch['postimage'], batch['postmask'], batch['premask']\n",
    "\n",
    "                preimage = preimage.to(device=device, dtype=torch.float32)\n",
    "                postimage = postimage.to(device=device, dtype=torch.float32)\n",
    "                post_masks = post_masks.to(device=device, dtype=torch.long)\n",
    "                pre_masks = pre_masks.to(device=device, dtype=torch.long)\n",
    "                \n",
    "                with torch.cuda.amp.autocast(enabled=ampbool):\n",
    "                    masks_pred = None\n",
    "                    if traintype == 'both':\n",
    "                        masks_pred = net(preimage, postimage)\n",
    "                        loss = criterion(masks_pred, post_masks)\n",
    "                        loss += dice_loss(\n",
    "                            F.softmax(masks_pred, dim=1).float()[:, 1:, ...],\n",
    "                            F.one_hot(post_masks, 5).permute(0, 3, 1, 2).float()[:, 1:, ...],\n",
    "                            multiclass=True\n",
    "                        )\n",
    "                    elif traintype == 'pre':\n",
    "                        masks_pred = net(preimage)\n",
    "                        loss = criterion(masks_pred, pre_masks)\n",
    "                        loss += dice_loss(\n",
    "                            F.softmax(masks_pred, dim=1).float(),\n",
    "                            F.one_hot(pre_masks, 2).permute(0, 3, 1, 2).float(),\n",
    "                            multiclass=True\n",
    "                        )\n",
    "                    elif traintype == 'post':\n",
    "                        masks_pred = net(postimage)\n",
    "                        loss = criterion(masks_pred, post_masks)\n",
    "                        loss += dice_loss(\n",
    "                            F.softmax(masks_pred, dim=1).float()[:, 1:, ...],\n",
    "                            F.one_hot(post_masks, 5).permute(0, 3, 1, 2).float()[:, 1:, ...],\n",
    "                            multiclass=True\n",
    "                        )\n",
    "\n",
    "                grad_scaler.scale(loss).backward()\n",
    "                grad_scaler.step(optimizer)\n",
    "                grad_scaler.update()\n",
    "                \n",
    "                # Update metrics\n",
    "                accuracy.update(masks_pred, post_masks)\n",
    "                precision.update(masks_pred, post_masks)\n",
    "                recall.update(masks_pred, post_masks)\n",
    "                \n",
    "                avg_loss += loss.item()\n",
    "                avg_acc += accuracy.compute().item()\n",
    "                avg_prec += precision.compute().item()\n",
    "                avg_rec += recall.compute().item()\n",
    "                \n",
    "                pbar.update(postimage.shape[0])\n",
    "                global_step += 1\n",
    "                \n",
    "                if math.isnan(loss.item()):\n",
    "                    nancount += 1\n",
    "                pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "                pbar.set_postfix_str(f'train accuracy: {avg_acc / (global_step * batch_size):.3f}, '\n",
    "                                     f'loss: {avg_loss / global_step:.3f}, '\n",
    "                                     f'prec: {avg_prec / global_step:.3f}, '\n",
    "                                     f'rec: {avg_rec / global_step:.3f}')\n",
    "                        \n",
    "        # Evaluate metrics\n",
    "        val_score = accuracy.compute()\n",
    "        val_prec = precision.compute()\n",
    "        val_rec = recall.compute()\n",
    "        val_loss = evaluate(net, dataloader=val_loader, device=device, ampbool=ampbool, traintype=traintype)\n",
    "\n",
    "        scheduler.step(val_score)\n",
    "        \n",
    "        print(f'Epoch {epoch}')\n",
    "        print(f'Validation Accuracy: {val_score:.4f}')\n",
    "        print(f'Validation Precision: {val_prec:.4f}')\n",
    "        print(f'Validation Recall: {val_rec:.4f}')\n",
    "        print(f'Validation Loss: {val_loss:.4f}')\n",
    "        print(f'Epoch Loss: {epoch_loss / n_train:.4f}')\n",
    "        print(f'NaN Count: {nancount}')\n",
    "\n",
    "        if save_checkpoint:\n",
    "            Path(dir_checkpoint).mkdir(parents=True, exist_ok=True)\n",
    "            torch.save(net.state_dict(), str(dir_checkpoint / f'branch12checkpoint_epoch_{epoch}.pth'))\n",
    "            logging.info(f'Checkpoint {epoch} saved!')\n"
   ],
   "id": "cf171a33a2c07a5a",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T14:33:29.059441Z",
     "start_time": "2024-09-03T14:33:29.052820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classes = 5\n",
    "bilinear = True\n",
    "loadstate = False\n",
    "# loadstate = True\n",
    "load = './checkpoints/Vgg19SiamConc/checkpoint_epoch12.pth'\n",
    "start_epoch = 13\n",
    "epochs = 20\n",
    "batch_size = 1\n",
    "lr = 1e-6\n",
    "scale = 1\n",
    "train =0.15259598603*2\n",
    "val = 1\n",
    "ampbool = True\n",
    "save_checkpoint = True\n",
    "traintype = 'both'\n",
    "gradclip = 1.0"
   ],
   "id": "abbc24f28ad0b659",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T14:33:32.113524Z",
     "start_time": "2024-09-03T14:33:32.107644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def confusionmatrix(pred,true):\n",
    "    result = np.zeros((5,5))\n",
    "    for i in range(true.shape[1]):\n",
    "        for j in range(true.shape[2]):\n",
    "            result[true[0][i][j]][pred[0][i][j]] +=1\n",
    "    return result"
   ],
   "id": "7e9ed12de022451e",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T14:33:33.527306Z",
     "start_time": "2024-09-03T14:33:33.504503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def modelconfusionmatrix(filepath,net,train_percent,val_percent):\n",
    "    device = 'cuda'\n",
    "    net.load_state_dict(torch.load(filepath, map_location=device))\n",
    "    net.to(device=device)\n",
    "    net.eval() # 评估模式\n",
    "    \n",
    "    # 新增的\n",
    "    train = None\n",
    "    validate = None\n",
    "    \n",
    "    try:\n",
    "        train = SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, 1, values =  [[.8,1.5], True, True,True], probabilities = [0,0,0,0])\n",
    "        validate = SatelliteDataset(pre_dir_val_img, pre_dir_val_mask,post_dir_val_img, post_dir_val_mask, 1, values =  [[1,1], False, False, False], probabilities = [0,0,0,0])\n",
    "        # train = SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, 1, values =  [[.8,1.5], True, True,True], probabilities = [0,0,0,0],increase = 0 ,mask_suffix = '.png',normalizemodel = 'vgg19')\n",
    "        # validate = SatelliteDataset(pre_dir_val_img, pre_dir_val_mask,post_dir_val_img, post_dir_val_mask, 1, values =  [[1,1], False, False, False], probabilities = [0,0,0,0],increase = 0,mask_suffix = '.png', normalizemodel = 'vgg19')\n",
    "    except (AssertionError, RuntimeError):\n",
    "        print('error')\n",
    "\n",
    "    loader_args = dict(batch_size=1, num_workers=1, pin_memory=True)        \n",
    "        \n",
    "    # 2. Split into train / validation partitions\n",
    "    n_train = int(len(train) * train_percent)\n",
    "    n_train_none = int(len(train) - n_train)\n",
    "    n_val = int(len(validate) * val_percent)\n",
    "    n_val_none = int(len(validate) - n_val)\n",
    "\n",
    "    train_set, train_val_none_set = random_split(train, [n_train, n_train_none], generator=torch.Generator().manual_seed(0))\n",
    "    \n",
    "    train_loader = DataLoader(train_set, shuffle=True, **loader_args)    \n",
    "\n",
    "    val_set, val_none_set = random_split(validate, [n_val, n_val_none], generator=torch.Generator().manual_seed(0))    \n",
    "\n",
    "    val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args) \n",
    "    resulttrain = torch.zeros(5,5).to(device)\n",
    "    resultval = torch.zeros(5,5).to(device)\n",
    "\n",
    "    num_val_batches = len(val_loader)\n",
    "    num_train_batches = len(train_loader)\n",
    "    confmat = ConfusionMatrix(task=\"multiclass\", num_classes=5).to(device)\n",
    "\n",
    "    with tqdm(total=num_train_batches, desc='train', unit='img') as pbar:\n",
    "        for batch in train_loader:\n",
    "            preimage, postimage, true_masks = batch['preimage'], batch['postimage'], batch['postmask']\n",
    "            # preimage, postimage, true_masks = batch['preimage'], batch['image'], batch['mask']\n",
    "            preimage = preimage.to(device=device, dtype=torch.float32)\n",
    "            postimage = postimage.to(device=device, dtype=torch.float32)\n",
    "            true_masks = true_masks.to(device=device, dtype=torch.long)\n",
    "            mask_true = F.one_hot(true_masks, 5).permute(0,3, 1, 2).float()\n",
    "            with torch.cuda.amp.autocast(enabled = True):\n",
    "                # predict the mask\n",
    "                mask_pred = net(preimage,postimage)\n",
    "                # convert to one-hot format\n",
    "                pred = F.softmax(mask_pred, dim=1).int().argmax(-3)\n",
    "                true = F.one_hot(true_masks, 5).int().permute(0, 3, 1, 2).argmax(-3)\n",
    "                resulttrain += confmat(pred,true)\n",
    "            pbar.update(postimage.shape[0])\n",
    "    print(resulttrain)\n",
    "    with tqdm(total=num_val_batches, desc='validation', unit='img') as pbar:\n",
    "        for batch in val_loader:\n",
    "            preimage, postimage, true_masks = batch['preimage'], batch['image'], batch['mask']\n",
    "            preimage = preimage.to(device=device, dtype=torch.float32)\n",
    "            postimage = postimage.to(device=device, dtype=torch.float32)\n",
    "            true_masks = true_masks.to(device=device, dtype=torch.long)\n",
    "            mask_true = F.one_hot(true_masks, 5).permute(0,3, 1, 2).float()\n",
    "            with torch.cuda.amp.autocast(enabled = True):\n",
    "                # predict the mask\n",
    "                mask_pred = net(preimage,postimage)\n",
    "                # convert to one-hot format\n",
    "                pred = F.softmax(mask_pred, dim=1).int().argmax(-3)\n",
    "                true = F.one_hot(true_masks, 5).int().permute(0, 3, 1, 2).argmax(-3)\n",
    "                resultval += confmat(pred,true)\n",
    "            pbar.update(postimage.shape[0])\n",
    "    print(resultval)\n",
    "    net.train()\n",
    "\n",
    "    # Fixes a potential division by zero error\n",
    "    if num_val_batches == 0:\n",
    "        return resulttrain,resultval\n",
    "    return resulttrain,resultval"
   ],
   "id": "b948416bc246378b",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T14:33:36.277164Z",
     "start_time": "2024-09-03T14:33:36.260113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def EvaluateFolder(folderpath,net,train_percent,val_percent):\n",
    "    in_files = [folderpath + s for s in os.listdir(folderpath)]\n",
    "    try:\n",
    "        train = SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, 1, values =  [[.8,1.5], True, True,True], probabilities = [0,0,0,0])\n",
    "        # train = SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, 1, values =  [[.8,1.5], True, True,True], probabilities = [0,0,0,0],increase = 0 ,mask_suffix = '.png',normalizemodel = 'vgg19')\n",
    "        validate = SatelliteDataset(pre_dir_val_img, pre_dir_val_mask,post_dir_val_img, post_dir_val_mask, 1, values =  [[1,1], False, False, False], probabilities = [0,0,0,0]) \n",
    "        # validate = SatelliteDataset(pre_dir_val_img, pre_dir_val_mask,post_dir_val_img, post_dir_val_mask, 1, values =  [[1,1], False, False, False], probabilities = [0,0,0,0],increase = 0,mask_suffix = '.png', normalizemodel = 'vgg19')\n",
    "    except (AssertionError, RuntimeError):\n",
    "        print('error')\n",
    "\n",
    "    loader_args = dict(batch_size=1, num_workers=1, pin_memory=True)        \n",
    "        \n",
    "    # 2. Split into train / validation partitions\n",
    "    n_train = int(len(train) * train_percent)\n",
    "    n_train_none = int(len(train) - n_train)\n",
    "    n_val = int(len(validate) * val_percent)\n",
    "    n_val_none = int(len(validate) - n_val)\n",
    "\n",
    "    train_set, train_val_none_set = random_split(train, [n_train, n_train_none], generator=torch.Generator().manual_seed(0))\n",
    "    \n",
    "    train_loader = DataLoader(train_set, shuffle=True, **loader_args)    \n",
    "\n",
    "    val_set, val_none_set = random_split(validate, [n_val, n_val_none], generator=torch.Generator().manual_seed(0))    \n",
    "\n",
    "    val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    loader_args = dict(batch_size=1, num_workers=1, pin_memory=True)        \n",
    "    \n",
    "    for i in in_files:\n",
    "        net.load_state_dict(torch.load(i, map_location=device))\n",
    "        net.to(device=device)\n",
    "        val_score, val_classes,val_loss = evaluate(net,dataloader = val_loader,device = device,ampbool = True,traintype = 'both')\n",
    "        train_score, train_classes,train_loss = evaluate(net,dataloader = train_loader,device = device,ampbool = True,traintype = 'both')\n",
    "        print('Train: ' + i)\n",
    "        print(train_score)\n",
    "        print(train_classes)\n",
    "        print(train_loss)\n",
    "        print('Validation: ' + i)\n",
    "        print(val_score)\n",
    "        print(val_classes)\n",
    "        print(val_loss)"
   ],
   "id": "68343e76dce750c1",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T14:33:41.752053Z",
     "start_time": "2024-09-03T14:33:38.584034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# net = SiamUNetConCVgg19()\n",
    "net = SiameseUNetWithResnet50Encoder()"
   ],
   "id": "96d2349ef657b1a4",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T13:43:40.540946Z",
     "start_time": "2024-09-03T13:43:40.456026Z"
    }
   },
   "cell_type": "code",
   "source": "EvaluateFolder('./checkpoints/Final/',net,train,val)",
   "id": "6693f5575c23882e",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: './checkpoints/Final/'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[22], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m EvaluateFolder(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./checkpoints/Final/\u001B[39m\u001B[38;5;124m'\u001B[39m,net,train,val)\n",
      "Cell \u001B[1;32mIn[19], line 2\u001B[0m, in \u001B[0;36mEvaluateFolder\u001B[1;34m(folderpath, net, train_percent, val_percent)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mEvaluateFolder\u001B[39m(folderpath,net,train_percent,val_percent):\n\u001B[1;32m----> 2\u001B[0m     in_files \u001B[38;5;241m=\u001B[39m [folderpath \u001B[38;5;241m+\u001B[39m s \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m os\u001B[38;5;241m.\u001B[39mlistdir(folderpath)]\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m      4\u001B[0m         train \u001B[38;5;241m=\u001B[39m SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, \u001B[38;5;241m1\u001B[39m, values \u001B[38;5;241m=\u001B[39m  [[\u001B[38;5;241m.8\u001B[39m,\u001B[38;5;241m1.5\u001B[39m], \u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;28;01mTrue\u001B[39;00m,\u001B[38;5;28;01mTrue\u001B[39;00m], probabilities \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m0\u001B[39m])\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 3] 系统找不到指定的路径。: './checkpoints/Final/'"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T14:33:41.772044Z",
     "start_time": "2024-09-03T14:33:41.763056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])"
   ],
   "id": "65f38a4fc06055b2",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T14:33:41.806888Z",
     "start_time": "2024-09-03T14:33:41.793729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mem_params = sum([param.nelement()*param.element_size() for param in net.parameters()])\n",
    "mem_bufs = sum([buf.nelement()*buf.element_size() for buf in net.buffers()])\n",
    "mem = mem_params + mem_bufs\n",
    "mem"
   ],
   "id": "cc9435c0dde00a3f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "553700636"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-09-03T14:58:50.111279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "    #net = SiamUNetDiff()\n",
    "    #net = SiamUNetConC()\n",
    "    #net = SiameseUNetWithResnet50Encoder()\n",
    "    #net = SiamUnet_diff_Full(3,5)\n",
    "    #net = UNetWithResnet50Encoder(5,'custom','./checkpoints/Resnet50ContrastiveWeight/checkpoint_epoch0.pth')\n",
    "    #net = UNet(out_classes=classes, up_sample_mode='conv_transpose',batch_norm=False)\n",
    "    #net = SiameseUNet(n_channels=3, n_classes = classes, bilinear=bilinear)\n",
    "    #net = UNetVgg19V2(out_classes=classes, up_sample_mode='conv_transpose')\n",
    "    #net = vgg19bn_unet(5,True)\n",
    "    #net = vgg19nobn_unet(5,True)\n",
    "    #net = vgg19nobn_unetdouble(5,True)\n",
    "    #net = VGGUnet19nobnspace(out_channels = 5, pretrained = True)\n",
    "    #net = SiamUNetCombVgg19()\n",
    "    ### 之前是用这个 net = SiamUNetConCVgg19()\n",
    "    #net = resnet_unet()\n",
    "    #net = VGG16Unet(out_channels = 5)\n",
    "    #net = resnet_siamunet()\n",
    "    #net = SiamUNetDiffVgg19()\n",
    "    #net = SiamUNetFullConCVgg19()\n",
    "    #net = SiamUNetConCResnet50(True,5)\n",
    "    #net = UNETResnet50(True,2)\n",
    "    '''net = smp.Unet(\n",
    "        encoder_name='resnext101_32x8d',\n",
    "        encoder_depth=5,\n",
    "        encoder_weights='imagenet',\n",
    "        decoder_use_batchnorm=False,\n",
    "        decoder_channels=(1024,512,256,128, 64),\n",
    "        decoder_attention_type=None,\n",
    "        in_channels=3,\n",
    "        classes=5,\n",
    "        activation=None,\n",
    "        aux_params=None\n",
    "    )\n",
    "    '''\n",
    "    if loadstate:\n",
    "        net.load_state_dict(torch.load(load, map_location=device))\n",
    "        logging.info(f'Model loaded from {load}')\n",
    "\n",
    "    net.to(device=device)\n",
    "    train_net(net=net,\n",
    "                  start_epoch = start_epoch,\n",
    "                  epochs=epochs,\n",
    "                  batch_size=batch_size,\n",
    "                  learning_rate=lr,\n",
    "                  device=device,\n",
    "                  img_scale=scale,\n",
    "                  train_percent = train,\n",
    "                  val_percent=val,\n",
    "                  save_checkpoint = save_checkpoint,\n",
    "                  ampbool = ampbool,\n",
    "                  traintype = traintype,\n",
    "                  gradient_clipping=gradclip)"
   ],
   "id": "a1fb80075cdc127b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liuyi\\AppData\\Local\\Temp\\ipykernel_47644\\1853108436.py:51: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  grad_scaler = torch.cuda.amp.GradScaler(enabled=ampbool)\n",
      "Epoch 13/20:   0%|          | 0/854 [00:00<?, ?img/s]C:\\Users\\liuyi\\AppData\\Local\\Temp\\ipykernel_47644\\1853108436.py:83: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=ampbool):\n",
      "Epoch 13/20:   0%|          | 1/854 [01:03<15:03:26, 63.55s/img, train accuracy: 0.008, loss: 2.969, prec: 0.200, rec: 0.002]"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
