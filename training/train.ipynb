{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-08T08:23:11.738946Z",
     "start_time": "2024-09-08T08:22:50.622600Z"
    }
   },
   "source": [
    "from model.my_models import SiameseUNetWithResnet50Encoder\n",
    "from model.evaluate import evaluate\n",
    "from utils.data_loading import SatelliteDataset\n",
    "from utils.dice_score import dice_loss\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.losses.focal import FocalLoss\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from torchvision import transforms\n",
    "from torchmetrics import ConfusionMatrix\n",
    "from torch import optim\n",
    "\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T16:02:22.980934800Z",
     "start_time": "2024-09-03T06:18:38.249088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# in tensorboard see the architecture of model \n",
    "# vit对输入图像大小有严格要求，需要是32的倍数，所以这里使用256*256的图像\n",
    "from torchvision.models import resnet50\n",
    "#tensorboard\n",
    "#命令行输入 tensorboard --logdir=./training/runs\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('./runs')\n",
    "model = SiameseUNetWithResnet50Encoder()\n",
    "\n",
    "# 定义输入张量，假设输入为两张 256x256 的 RGB 图像\n",
    "input_1 = torch.rand(1, 3, 256, 256)\n",
    "input_2 = torch.rand(1, 3, 256, 256)\n",
    "# 不加torch.no_grad()会报错\n",
    "with torch.no_grad():\n",
    "    writer.add_graph(model, (input_1, input_2))\n",
    "# with torch.no_grad():\n",
    "#     writer.add_graph(model, input_to_model = torch.rand(1, 3, 256, 256))\n",
    "writer.close()"
   ],
   "id": "a7086be02cebd151",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liuyi\\segment\\damage-assessment\\model\\my_functions.py:34: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if(diffY<0):\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T16:28:27.568190Z",
     "start_time": "2024-09-05T16:28:27.560878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# img_home_path = \"C:/Users/liuyi/segment/ubdd/xbd/Dataset\"\n",
    "img_home_path = \"C:/Users/liuyi/segment/ubdd/xbd/Dataset_test\"\n",
    "post_dir_img = img_home_path + \"/TierFull/Post/Image512/\"\n",
    "post_dir_mask = img_home_path + \"/TierFull/Post/Label512/\"\n",
    "pre_dir_img = img_home_path + \"/TierFull/Pre/Image512/\"\n",
    "pre_dir_mask = img_home_path + \"/TierFull/Pre/Label512/\"\n",
    "post_dir_val_img = img_home_path + \"/Validation/Post/Image512/\"\n",
    "post_dir_val_mask = img_home_path + \"/Validation/Post/Label512/\"\n",
    "pre_dir_val_img = img_home_path + \"/Validation/Pre/Image512/\"\n",
    "pre_dir_val_mask = img_home_path + \"/Validation/Pre/Label512/\"\n",
    "post_dir_test_img = img_home_path + \"/Test/Post/Image512/\"\n",
    "post_dir_test_mask = img_home_path + \"/Test/Post/Label512/\"\n",
    "pre_dir_test_img = img_home_path + \"/Test/Pre/Image512/\"\n",
    "pre_dir_test_mask = img_home_path + \"/Test/Pre/Label512/\"\n",
    "# post_dir_img = Path('.\\\\Dataset\\\\TierFull\\\\Post\\\\Image512\\\\')\n",
    "# post_dir_mask = Path('.\\\\Dataset\\\\TierFull\\\\Post\\\\Label512\\\\')\n",
    "# pre_dir_img = Path('.\\\\Dataset\\\\TierFull\\\\Pre\\\\Image512\\\\')\n",
    "# pre_dir_mask = Path('.\\\\Dataset\\\\TierFull\\\\Pre\\\\Label512\\\\')\n",
    "# post_dir_val_img = Path('.\\\\Dataset\\\\Validation\\\\Post\\\\Image512\\\\')\n",
    "# post_dir_val_mask = Path('.\\\\Dataset\\\\Validation\\\\Post\\\\Label512\\\\')\n",
    "# pre_dir_val_img = Path('.\\\\Dataset\\\\Validation\\\\Pre\\\\Image512\\\\')\n",
    "# pre_dir_val_mask = Path('.\\\\Dataset\\\\Validation\\\\Pre\\\\Label512\\\\')\n",
    "dir_checkpoint = Path('checkpoints/v_1.1_lr_10-4/')\n",
    "# dir_checkpoint = Path('checkpoints/v_1.0_lr_10-6/')"
   ],
   "id": "facb3659ae0b68",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T16:28:27.582364Z",
     "start_time": "2024-09-05T16:28:27.576240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "closs = nn.CrossEntropyLoss()\n",
    "\n",
    "floss = FocalLoss(mode = 'multiclass',\n",
    "                alpha = None,\n",
    "                gamma = 2.0,\n",
    "                ignore_index = None,\n",
    "                reduction = \"mean\",\n",
    "                normalized = False,\n",
    "                reduced_threshold = None)"
   ],
   "id": "a1606a6cbf45f917",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-03T14:31:26.286688Z",
     "start_time": "2024-09-03T14:31:23.756686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_class_weights():\n",
    "    train = SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, 1, values =  [[1,1], True, True, True], probabilities = [.5,.5,.5,0,0,0,0])\n",
    "    # 设置DataLoader\n",
    "    loader_args = dict(batch_size=1, num_workers=1, pin_memory=True)        \n",
    "    train_loader = DataLoader(train, shuffle=True, **loader_args)\n",
    "     # 用于统计每个类别的频次，假设有5个类别\n",
    "    classes = torch.zeros(5)\n",
    "    with tqdm(total=len(train_loader), unit='img') as pbar:\n",
    "        for batch in train_loader:\n",
    "            image = batch['premask'].int() # 获取mask\n",
    "            count = torch.bincount(torch.flatten(image),minlength = 5)\n",
    "            classes = classes.add(count)\n",
    "            pbar.update(image.shape[0])\n",
    "    return torch.div(classes,torch.sum(classes))\n",
    "print(get_class_weights())"
   ],
   "id": "c5bd79b74dcc1a11",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2800 [00:05<?, ?img/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 16\u001B[0m\n\u001B[0;32m     14\u001B[0m             pbar\u001B[38;5;241m.\u001B[39mupdate(image\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m])\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mdiv(classes,torch\u001B[38;5;241m.\u001B[39msum(classes))\n\u001B[1;32m---> 16\u001B[0m \u001B[38;5;28mprint\u001B[39m(get_class_weights())\n",
      "Cell \u001B[1;32mIn[31], line 10\u001B[0m, in \u001B[0;36mget_class_weights\u001B[1;34m()\u001B[0m\n\u001B[0;32m      8\u001B[0m classes \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;241m5\u001B[39m)\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tqdm(total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(train_loader), unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimg\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m pbar:\n\u001B[1;32m---> 10\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[0;32m     11\u001B[0m         image \u001B[38;5;241m=\u001B[39m batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpremask\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mint() \u001B[38;5;66;03m# 获取mask\u001B[39;00m\n\u001B[0;32m     12\u001B[0m         count \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mbincount(torch\u001B[38;5;241m.\u001B[39mflatten(image),minlength \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m5\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\xbdtwostep\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    628\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 630\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_data()\n\u001B[0;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\xbdtwostep\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1327\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1324\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_data(data)\n\u001B[0;32m   1326\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shutdown \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m-> 1327\u001B[0m idx, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_data()\n\u001B[0;32m   1328\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1329\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable:\n\u001B[0;32m   1330\u001B[0m     \u001B[38;5;66;03m# Check for _IterableDatasetStopIteration\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\xbdtwostep\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1283\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._get_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1281\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m   1282\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_thread\u001B[38;5;241m.\u001B[39mis_alive():\n\u001B[1;32m-> 1283\u001B[0m         success, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_try_get_data()\n\u001B[0;32m   1284\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m success:\n\u001B[0;32m   1285\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\xbdtwostep\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1131\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m   1118\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_try_get_data\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m_utils\u001B[38;5;241m.\u001B[39mMP_STATUS_CHECK_INTERVAL):\n\u001B[0;32m   1119\u001B[0m     \u001B[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001B[39;00m\n\u001B[0;32m   1120\u001B[0m     \u001B[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1128\u001B[0m     \u001B[38;5;66;03m# Returns a 2-tuple:\u001B[39;00m\n\u001B[0;32m   1129\u001B[0m     \u001B[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001B[39;00m\n\u001B[0;32m   1130\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1131\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_queue\u001B[38;5;241m.\u001B[39mget(timeout\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[0;32m   1132\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m, data)\n\u001B[0;32m   1133\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1134\u001B[0m         \u001B[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001B[39;00m\n\u001B[0;32m   1135\u001B[0m         \u001B[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001B[39;00m\n\u001B[0;32m   1136\u001B[0m         \u001B[38;5;66;03m# worker failures.\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\xbdtwostep\\Lib\\queue.py:180\u001B[0m, in \u001B[0;36mQueue.get\u001B[1;34m(self, block, timeout)\u001B[0m\n\u001B[0;32m    178\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m remaining \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m:\n\u001B[0;32m    179\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m Empty\n\u001B[1;32m--> 180\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnot_empty\u001B[38;5;241m.\u001B[39mwait(remaining)\n\u001B[0;32m    181\u001B[0m item \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get()\n\u001B[0;32m    182\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnot_full\u001B[38;5;241m.\u001B[39mnotify()\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\xbdtwostep\\Lib\\threading.py:331\u001B[0m, in \u001B[0;36mCondition.wait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    330\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 331\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m waiter\u001B[38;5;241m.\u001B[39macquire(\u001B[38;5;28;01mTrue\u001B[39;00m, timeout)\n\u001B[0;32m    332\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    333\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m waiter\u001B[38;5;241m.\u001B[39macquire(\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T16:28:27.624449Z",
     "start_time": "2024-09-05T16:28:27.592373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import torchmetrics\n",
    "import numpy as np\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train_net(net,\n",
    "              device,\n",
    "              start_epoch: int = 1,\n",
    "              epochs: int = 5,\n",
    "              batch_size: int = 1,\n",
    "              learning_rate: float = 1e-5,\n",
    "              train_percent: float = 1,\n",
    "              val_percent: float = 1,\n",
    "              test_percent: float = 1,\n",
    "              save_checkpoint: bool = True,\n",
    "              img_scale: float = 0.5,\n",
    "              ampbool: bool = False,\n",
    "              traintype: str = 'post',\n",
    "              gradient_clipping: float = 1.0):\n",
    "    # 1. Create dataset\n",
    "    train = None\n",
    "    validate = None\n",
    "    test_set = None\n",
    "    try:\n",
    "        train = SatelliteDataset(pre_dir_img, pre_dir_mask, post_dir_img, post_dir_mask, 1, values=[[.8,1.5], True, True, True], probabilities=[0, 0, 0, 0])\n",
    "        validate = SatelliteDataset(pre_dir_val_img, pre_dir_val_mask, post_dir_val_img, post_dir_val_mask, 1, values=[[1, 1], False, False, False], probabilities=[0, 0, 0, 0])\n",
    "        test_set = SatelliteDataset(pre_dir_test_img, pre_dir_test_mask, post_dir_test_img, post_dir_test_mask, 1, values=[[1, 1], False, False, False], probabilities=[0, 0, 0, 0])\n",
    "    except (AssertionError, RuntimeError):\n",
    "        print('Error creating datasets')\n",
    "\n",
    "    loader_args = dict(batch_size=batch_size, num_workers=1, pin_memory=True)\n",
    "    \n",
    "    # 2. Split into train / validation partitions\n",
    "    n_train = int(len(train) * train_percent)\n",
    "    n_train_none = int(len(train) - n_train)\n",
    "    n_val = int(len(validate) * val_percent)\n",
    "    n_val_none = int(len(validate) - n_val)\n",
    "    n_test = int(len(test_set) * test_percent)\n",
    "    n_test_none = int(len(test_set) - n_test)\n",
    "\n",
    "    train_set, train_val_none_set = random_split(train, [n_train, n_train_none], generator=torch.Generator().manual_seed(0))\n",
    "    train_loader = DataLoader(train_set, shuffle=True, **loader_args)\n",
    "\n",
    "    val_set, val_none_set = random_split(validate, [n_val, n_val_none], generator=torch.Generator().manual_seed(0))\n",
    "    val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)\n",
    "    \n",
    "    test_set, test_none_set = random_split(test_set, [n_test, n_test_none], generator=torch.Generator().manual_seed(0))\n",
    "    test_loader = DataLoader(test_set, shuffle=False, drop_last=True, **loader_args)\n",
    "\n",
    "    # 4. Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n",
    "    optimizer = optim.RMSprop(net.parameters(), lr=learning_rate, weight_decay=1e-6, momentum=0.9, foreach=True)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[3,6,9,12,15,18,19,20,33,47,50,60,70,90,110,130,150,170,180,190], gamma=0.5)\n",
    "    grad_scaler = torch.amp.GradScaler('cuda', enabled=ampbool)\n",
    "    criterion = closs\n",
    "    \n",
    "    # 5. Initialize torchmetrics metrics\n",
    "    train_accuracy = torchmetrics.Accuracy(task='multiclass', num_classes=5, validate_args=False).to(device)\n",
    "    train_precision = torchmetrics.Precision(task='multiclass', num_classes=5, average='macro', validate_args=False).to(device)\n",
    "    train_recall = torchmetrics.Recall(task='multiclass', num_classes=5, average='macro', validate_args=False).to(device)\n",
    "    \n",
    "    #TODO: 是否加入早停\n",
    "    #early_stopping = EarlyStopping(patience=3, verbose=True)\n",
    "\n",
    "    # 6. Begin training\n",
    "    for epoch in range(start_epoch, start_epoch + epochs):\n",
    "        net.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_steps = 0\n",
    "        nancount = 0\n",
    "        with tqdm(total=n_train, desc=f'Epoch {epoch}/{epochs}', unit='img') as pbar:\n",
    "            for batch in train_loader:\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                preimage, postimage, post_masks, pre_masks = batch['preimage'], batch['postimage'], batch['postmask'], batch['premask']\n",
    "\n",
    "                preimage = preimage.to(device=device, dtype=torch.float32)\n",
    "                postimage = postimage.to(device=device, dtype=torch.float32)\n",
    "                post_masks = post_masks.to(device=device, dtype=torch.long)\n",
    "                pre_masks = pre_masks.to(device=device, dtype=torch.long)\n",
    "                \n",
    "                with torch.amp.autocast('cuda', enabled=ampbool):\n",
    "                    masks_pred = None\n",
    "                    if traintype == 'both':\n",
    "                        masks_pred = net(preimage, postimage)\n",
    "                        loss = criterion(masks_pred, post_masks)\n",
    "                        loss += dice_loss(\n",
    "                            F.softmax(masks_pred, dim=1).float()[:, 1:, ...],\n",
    "                            F.one_hot(post_masks, 5).permute(0, 3, 1, 2).float()[:, 1:, ...],\n",
    "                            multiclass=True\n",
    "                        )\n",
    "                    elif traintype == 'pre':\n",
    "                        masks_pred = net(preimage)\n",
    "                        loss = criterion(masks_pred, pre_masks)\n",
    "                        loss += dice_loss(\n",
    "                            F.softmax(masks_pred, dim=1).float(),\n",
    "                            F.one_hot(pre_masks, 2).permute(0, 3, 1, 2).float(),\n",
    "                            multiclass=True\n",
    "                        )\n",
    "                    elif traintype == 'post':\n",
    "                        masks_pred = net(postimage)\n",
    "                        loss = criterion(masks_pred, post_masks)\n",
    "                        loss += dice_loss(\n",
    "                            F.softmax(masks_pred, dim=1).float()[:, 1:, ...],\n",
    "                            F.one_hot(post_masks, 5).permute(0, 3, 1, 2).float()[:, 1:, ...],\n",
    "                            multiclass=True\n",
    "                        )\n",
    "\n",
    "                grad_scaler.scale(loss).backward()\n",
    "                grad_scaler.step(optimizer)\n",
    "                grad_scaler.update()\n",
    "                \n",
    "                # Update metrics\n",
    "                train_accuracy.update(masks_pred, post_masks)\n",
    "                train_precision.update(masks_pred, post_masks)\n",
    "                train_recall.update(masks_pred, post_masks)\n",
    "                \n",
    "                pbar.update(postimage.shape[0])\n",
    "                epoch_steps += 1 #已经处理的批次数\n",
    "                \n",
    "                if math.isnan(loss.item()):\n",
    "                    epoch_loss += 0\n",
    "                    nancount += 1\n",
    "                else:\n",
    "                    epoch_loss += loss.item()   \n",
    "                    \n",
    "                # if epoch_steps == 1 or epoch_steps % max(1, len(train_loader) // 10) == 0:\n",
    "                pbar.set_postfix(**{\n",
    "                    'loss (batch)': float(loss.item()),\n",
    "                    'loss': float(epoch_loss / epoch_steps),\n",
    "                    'accuracy': float(train_accuracy.compute().item()),\n",
    "                    'precision': float(train_precision.compute().item()),\n",
    "                    'recall': float(train_recall.compute().item())\n",
    "                })\n",
    "                \n",
    "        # 计算最终的训练指标\n",
    "        train_acc = train_accuracy.compute()\n",
    "        train_prec = train_precision.compute()\n",
    "        train_rec = train_recall.compute()\n",
    "        train_loss = epoch_loss / len(train_loader)\n",
    "        \n",
    "        # 使用现有的evaluate函数进行验证\n",
    "        val_score, val_class_scores, val_loss = evaluate(net, dataloader=val_loader, device=device, ampbool=ampbool, traintype=traintype)\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f'Epoch {epoch}')\n",
    "        print(f'Training - Accuracy: {train_acc:.4f}, Precision: {train_prec:.4f}, Recall: {train_rec:.4f}')\n",
    "        print(f'Training Loss: {train_loss:.4f}')\n",
    "        print(f'Validation - Dice Score: {val_score:.4f}')\n",
    "        print(f'Validation - Class Dice Scores: {[f\"{score:.4f}\" for score in val_class_scores]}')\n",
    "        print(f'Validation Loss: {val_loss:.4f}')\n",
    "        print(f'NaN Count: {nancount}')\n",
    "\n",
    "        if save_checkpoint:\n",
    "            Path(dir_checkpoint).mkdir(parents=True, exist_ok=True)\n",
    "            torch.save(net.state_dict(), str(dir_checkpoint / f'branch12checkpoint_epoch_{epoch}.pth'))\n",
    "            logging.info(f'Checkpoint {epoch} saved!')\n",
    "            \n",
    "    # Final evaluation on test set\n",
    "    test_score, test_class_scores, test_loss = evaluate(net, test_loader, device, ampbool, traintype)\n",
    "    print('Final Test Results:')\n",
    "    print(f'Test - Dice Score: {test_score:.4f}')\n",
    "    print(f'Test - Class Dice Scores: {[f\"{score:.4f}\" for score in test_class_scores]}')\n",
    "    print(f'Test Loss: {test_loss:.4f}')\n",
    "    # \n",
    "    # return train_loss, val_loss, test_loss\n"
   ],
   "id": "cf171a33a2c07a5a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T16:28:28.025317Z",
     "start_time": "2024-09-05T16:28:28.019239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classes = 5\n",
    "bilinear = True\n",
    "loadstate = False\n",
    "# loadstate = True\n",
    "load = './checkpoints/Vgg19SiamConc/checkpoint_epoch12.pth'\n",
    "start_epoch = 0\n",
    "# start_epoch = 13\n",
    "epochs = 20\n",
    "batch_size = 4\n",
    "lr = 1e-4\n",
    "# batch_size = 1\n",
    "# lr = 1e-6\n",
    "scale = 1\n",
    "train = 1\n",
    "# train =0.15259598603*2\n",
    "val = 1\n",
    "test = 1\n",
    "ampbool = True\n",
    "save_checkpoint = True\n",
    "traintype = 'both'\n",
    "gradclip = 1.0"
   ],
   "id": "abbc24f28ad0b659",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T16:28:28.047571Z",
     "start_time": "2024-09-05T16:28:28.041412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def confusionmatrix(pred,true):\n",
    "    result = np.zeros((5,5))\n",
    "    for i in range(true.shape[1]):\n",
    "        for j in range(true.shape[2]):\n",
    "            result[true[0][i][j]][pred[0][i][j]] +=1\n",
    "    return result"
   ],
   "id": "7e9ed12de022451e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T16:28:28.121066Z",
     "start_time": "2024-09-05T16:28:28.102633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def modelconfusionmatrix(filepath,net,train_percent,val_percent):\n",
    "    device = 'cuda'\n",
    "    net.load_state_dict(torch.load(filepath, map_location=device))\n",
    "    net.to(device=device)\n",
    "    net.eval() # 评估模式\n",
    "    \n",
    "    try:\n",
    "        train = SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, 1, values =  [[.8,1.5], True, True,True], probabilities = [0,0,0,0])\n",
    "        validate = SatelliteDataset(pre_dir_val_img, pre_dir_val_mask,post_dir_val_img, post_dir_val_mask, 1, values =  [[1,1], False, False, False], probabilities = [0,0,0,0])\n",
    "        # train = SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, 1, values =  [[.8,1.5], True, True,True], probabilities = [0,0,0,0],increase = 0 ,mask_suffix = '.png',normalizemodel = 'vgg19')\n",
    "        # validate = SatelliteDataset(pre_dir_val_img, pre_dir_val_mask,post_dir_val_img, post_dir_val_mask, 1, values =  [[1,1], False, False, False], probabilities = [0,0,0,0],increase = 0,mask_suffix = '.png', normalizemodel = 'vgg19')\n",
    "    except (AssertionError, RuntimeError):\n",
    "        print('error')\n",
    "\n",
    "    loader_args = dict(batch_size=1, num_workers=1, pin_memory=True)        \n",
    "        \n",
    "    # 2. Split into train / validation partitions\n",
    "    n_train = int(len(train) * train_percent)\n",
    "    n_train_none = int(len(train) - n_train)\n",
    "    n_val = int(len(validate) * val_percent)\n",
    "    n_val_none = int(len(validate) - n_val)\n",
    "\n",
    "    train_set, train_val_none_set = random_split(train, [n_train, n_train_none], generator=torch.Generator().manual_seed(0))\n",
    "    \n",
    "    train_loader = DataLoader(train_set, shuffle=True, **loader_args)    \n",
    "\n",
    "    val_set, val_none_set = random_split(validate, [n_val, n_val_none], generator=torch.Generator().manual_seed(0))    \n",
    "\n",
    "    val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args) \n",
    "    resulttrain = torch.zeros(5,5).to(device)\n",
    "    resultval = torch.zeros(5,5).to(device)\n",
    "\n",
    "    num_val_batches = len(val_loader)\n",
    "    num_train_batches = len(train_loader)\n",
    "    confmat = ConfusionMatrix(task=\"multiclass\", num_classes=5).to(device)\n",
    "\n",
    "    with tqdm(total=num_train_batches, desc='train', unit='img') as pbar:\n",
    "        for batch in train_loader:\n",
    "            preimage, postimage, true_masks = batch['preimage'], batch['postimage'], batch['postmask']\n",
    "            # preimage, postimage, true_masks = batch['preimage'], batch['image'], batch['mask']\n",
    "            preimage = preimage.to(device=device, dtype=torch.float32)\n",
    "            postimage = postimage.to(device=device, dtype=torch.float32)\n",
    "            true_masks = true_masks.to(device=device, dtype=torch.long)\n",
    "            mask_true = F.one_hot(true_masks, 5).permute(0,3, 1, 2).float()\n",
    "            with torch.amp.autocast('cuda', enabled = True):\n",
    "                # predict the mask\n",
    "                mask_pred = net(preimage,postimage)\n",
    "                # convert to one-hot format\n",
    "                pred = F.softmax(mask_pred, dim=1).int().argmax(-3)\n",
    "                true = F.one_hot(true_masks, 5).int().permute(0, 3, 1, 2).argmax(-3)\n",
    "                resulttrain += confmat(pred,true)\n",
    "            pbar.update(postimage.shape[0])\n",
    "    print(resulttrain)\n",
    "    with tqdm(total=num_val_batches, desc='validation', unit='img') as pbar:\n",
    "        for batch in val_loader:\n",
    "            preimage, postimage, true_masks = batch['preimage'], batch['postimage'], batch['postmask']\n",
    "            preimage = preimage.to(device=device, dtype=torch.float32)\n",
    "            postimage = postimage.to(device=device, dtype=torch.float32)\n",
    "            true_masks = true_masks.to(device=device, dtype=torch.long)\n",
    "            mask_true = F.one_hot(true_masks, 5).permute(0,3, 1, 2).float()\n",
    "            with torch.cuda.amp.autocast(enabled = True):\n",
    "                # predict the mask\n",
    "                mask_pred = net(preimage,postimage)\n",
    "                # convert to one-hot format\n",
    "                pred = F.softmax(mask_pred, dim=1).int().argmax(-3)\n",
    "                true = F.one_hot(true_masks, 5).int().permute(0, 3, 1, 2).argmax(-3)\n",
    "                resultval += confmat(pred,true)\n",
    "            pbar.update(postimage.shape[0])\n",
    "    print(resultval)\n",
    "    net.train()\n",
    "\n",
    "    # Fixes a potential division by zero error\n",
    "    if num_val_batches == 0:\n",
    "        return resulttrain,resultval\n",
    "    return resulttrain,resultval"
   ],
   "id": "b948416bc246378b",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T16:28:28.156380Z",
     "start_time": "2024-09-05T16:28:28.143450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def EvaluateFolder(folderpath,net,train_percent,val_percent):\n",
    "    in_files = [folderpath + s for s in os.listdir(folderpath)]\n",
    "    try:\n",
    "        train = SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, 1, values =  [[.8,1.5], True, True,True], probabilities = [0,0,0,0])\n",
    "        # train = SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, 1, values =  [[.8,1.5], True, True,True], probabilities = [0,0,0,0],increase = 0 ,mask_suffix = '.png',normalizemodel = 'vgg19')\n",
    "        validate = SatelliteDataset(pre_dir_val_img, pre_dir_val_mask,post_dir_val_img, post_dir_val_mask, 1, values =  [[1,1], False, False, False], probabilities = [0,0,0,0]) \n",
    "        # validate = SatelliteDataset(pre_dir_val_img, pre_dir_val_mask,post_dir_val_img, post_dir_val_mask, 1, values =  [[1,1], False, False, False], probabilities = [0,0,0,0],increase = 0,mask_suffix = '.png', normalizemodel = 'vgg19')\n",
    "    except (AssertionError, RuntimeError):\n",
    "        print('error')\n",
    "\n",
    "    loader_args = dict(batch_size=1, num_workers=1, pin_memory=True)        \n",
    "        \n",
    "    # 2. Split into train / validation partitions\n",
    "    n_train = int(len(train) * train_percent)\n",
    "    n_train_none = int(len(train) - n_train)\n",
    "    n_val = int(len(validate) * val_percent)\n",
    "    n_val_none = int(len(validate) - n_val)\n",
    "\n",
    "    train_set, train_val_none_set = random_split(train, [n_train, n_train_none], generator=torch.Generator().manual_seed(0))\n",
    "    \n",
    "    train_loader = DataLoader(train_set, shuffle=True, **loader_args)    \n",
    "\n",
    "    val_set, val_none_set = random_split(validate, [n_val, n_val_none], generator=torch.Generator().manual_seed(0))    \n",
    "\n",
    "    val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    loader_args = dict(batch_size=1, num_workers=1, pin_memory=True)        \n",
    "    \n",
    "    for i in in_files:\n",
    "        net.load_state_dict(torch.load(i, map_location=device))\n",
    "        net.to(device=device)\n",
    "        val_score, val_classes,val_loss = evaluate(net,dataloader = val_loader,device = device,ampbool = True,traintype = 'both')\n",
    "        train_score, train_classes,train_loss = evaluate(net,dataloader = train_loader,device = device,ampbool = True,traintype = 'both')\n",
    "        print('Train: ' + i)\n",
    "        print(train_score)\n",
    "        print(train_classes)\n",
    "        print(train_loss)\n",
    "        print('Validation: ' + i)\n",
    "        print(val_score)\n",
    "        print(val_classes)\n",
    "        print(val_loss)"
   ],
   "id": "68343e76dce750c1",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T16:28:29.426397Z",
     "start_time": "2024-09-05T16:28:28.172020Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# net = SiamUNetConCVgg19()\n",
    "net = SiameseUNetWithResnet50Encoder()"
   ],
   "id": "96d2349ef657b1a4",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T16:16:27.310403Z",
     "start_time": "2024-09-05T16:16:26.825386Z"
    }
   },
   "cell_type": "code",
   "source": "EvaluateFolder('./checkpoints/Final/',net,train,val)",
   "id": "6693f5575c23882e",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: './checkpoints/Final/'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m EvaluateFolder(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./checkpoints/Final/\u001B[39m\u001B[38;5;124m'\u001B[39m,net,train,val)\n",
      "Cell \u001B[1;32mIn[17], line 2\u001B[0m, in \u001B[0;36mEvaluateFolder\u001B[1;34m(folderpath, net, train_percent, val_percent)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mEvaluateFolder\u001B[39m(folderpath,net,train_percent,val_percent):\n\u001B[1;32m----> 2\u001B[0m     in_files \u001B[38;5;241m=\u001B[39m [folderpath \u001B[38;5;241m+\u001B[39m s \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m os\u001B[38;5;241m.\u001B[39mlistdir(folderpath)]\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m      4\u001B[0m         train \u001B[38;5;241m=\u001B[39m SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, \u001B[38;5;241m1\u001B[39m, values \u001B[38;5;241m=\u001B[39m  [[\u001B[38;5;241m.8\u001B[39m,\u001B[38;5;241m1.5\u001B[39m], \u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;28;01mTrue\u001B[39;00m,\u001B[38;5;28;01mTrue\u001B[39;00m], probabilities \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m0\u001B[39m])\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 3] 系统找不到指定的路径。: './checkpoints/Final/'"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T16:28:29.455505Z",
     "start_time": "2024-09-05T16:28:29.444819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])"
   ],
   "id": "65f38a4fc06055b2",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T16:28:29.487142Z",
     "start_time": "2024-09-05T16:28:29.473212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mem_params = sum([param.nelement()*param.element_size() for param in net.parameters()])\n",
    "mem_bufs = sum([buf.nelement()*buf.element_size() for buf in net.buffers()])\n",
    "mem = mem_params + mem_bufs\n",
    "mem"
   ],
   "id": "cc9435c0dde00a3f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "553700636"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T08:18:46.076718Z",
     "start_time": "2024-09-05T16:28:29.637340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "    #net = SiamUNetDiff()\n",
    "    #net = SiamUNetConC()\n",
    "    #net = SiameseUNetWithResnet50Encoder()\n",
    "    #net = SiamUnet_diff_Full(3,5)\n",
    "    #net = UNetWithResnet50Encoder(5,'custom','./checkpoints/Resnet50ContrastiveWeight/checkpoint_epoch0.pth')\n",
    "    #net = UNet(out_classes=classes, up_sample_mode='conv_transpose',batch_norm=False)\n",
    "    #net = SiameseUNet(n_channels=3, n_classes = classes, bilinear=bilinear)\n",
    "    #net = UNetVgg19V2(out_classes=classes, up_sample_mode='conv_transpose')\n",
    "    #net = vgg19bn_unet(5,True)\n",
    "    #net = vgg19nobn_unet(5,True)\n",
    "    #net = vgg19nobn_unetdouble(5,True)\n",
    "    #net = VGGUnet19nobnspace(out_channels = 5, pretrained = True)\n",
    "    #net = SiamUNetCombVgg19()\n",
    "    ### 之前是用这个 net = SiamUNetConCVgg19()\n",
    "    #net = resnet_unet()\n",
    "    #net = VGG16Unet(out_channels = 5)\n",
    "    #net = resnet_siamunet()\n",
    "    #net = SiamUNetDiffVgg19()\n",
    "    #net = SiamUNetFullConCVgg19()\n",
    "    #net = SiamUNetConCResnet50(True,5)\n",
    "    #net = UNETResnet50(True,2)\n",
    "    '''net = smp.Unet(\n",
    "        encoder_name='resnext101_32x8d',\n",
    "        encoder_depth=5,\n",
    "        encoder_weights='imagenet',\n",
    "        decoder_use_batchnorm=False,\n",
    "        decoder_channels=(1024,512,256,128, 64),\n",
    "        decoder_attention_type=None,\n",
    "        in_channels=3,\n",
    "        classes=5,\n",
    "        activation=None,\n",
    "        aux_params=None\n",
    "    )\n",
    "    '''\n",
    "    if loadstate:\n",
    "        net.load_state_dict(torch.load(load, map_location=device))\n",
    "        logging.info(f'Model loaded from {load}')\n",
    "\n",
    "    net.to(device=device)\n",
    "    train_net(net=net,\n",
    "                  start_epoch = start_epoch,\n",
    "                  epochs=epochs,\n",
    "                  batch_size=batch_size,\n",
    "                  learning_rate=lr,\n",
    "                  device=device,\n",
    "                  img_scale=scale,\n",
    "                  train_percent = train,\n",
    "                  val_percent=val,\n",
    "                  save_checkpoint = save_checkpoint,\n",
    "                  ampbool = ampbool,\n",
    "                  traintype = traintype,\n",
    "                  gradient_clipping=gradclip)"
   ],
   "id": "a1fb80075cdc127b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/20: 100%|██████████| 854/854 [3:24:55<00:00, 14.40s/img, accuracy=0.9, loss=2.05, loss (batch)=1.85, precision=0.199, recall=0.2]     \n",
      "validation: 100%|██████████| 934/934 [3:49:33<00:00, 14.75s/img, loss (batch)=3.66]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Training - Accuracy: 0.8999, Precision: 0.1993, Recall: 0.1999\n",
      "Training Loss: 2.0520\n",
      "Validation - Dice Score: 0.0863\n",
      "Validation - Class Dice Scores: ['0.9577', '0.1235', '0.0003', '0.0005', '0.2208']\n",
      "Validation Loss: 3.6638\n",
      "NaN Count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 854/854 [3:22:50<00:00, 14.25s/img, accuracy=0.92, loss=1.83, loss (batch)=1.74, precision=0.199, recall=0.2]   \n",
      "validation: 100%|██████████| 934/934 [3:48:25<00:00, 14.67s/img, loss (batch)=2.39]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Training - Accuracy: 0.9203, Precision: 0.1993, Recall: 0.2000\n",
      "Training Loss: 1.8327\n",
      "Validation - Dice Score: 0.3714\n",
      "Validation - Class Dice Scores: ['0.9587', '0.2838', '0.4348', '0.3985', '0.3684']\n",
      "Validation Loss: 2.3949\n",
      "NaN Count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 854/854 [3:34:30<00:00, 15.07s/img, accuracy=0.927, loss=1.7, loss (batch)=1.78, precision=0.199, recall=0.2]   \n",
      "validation: 100%|██████████| 934/934 [4:06:37<00:00, 15.84s/img, loss (batch)=1.9]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n",
      "Training - Accuracy: 0.9272, Precision: 0.1994, Recall: 0.2000\n",
      "Training Loss: 1.7027\n",
      "Validation - Dice Score: 0.3748\n",
      "Validation - Class Dice Scores: ['0.9624', '0.2656', '0.4027', '0.3856', '0.4454']\n",
      "Validation Loss: 1.9042\n",
      "NaN Count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 854/854 [6:20:50<00:00, 26.76s/img, accuracy=0.931, loss=1.57, loss (batch)=1.49, precision=0.199, recall=0.2]  \n",
      "validation: 100%|██████████| 934/934 [3:46:08<00:00, 14.53s/img, loss (batch)=1.65]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3\n",
      "Training - Accuracy: 0.9307, Precision: 0.1994, Recall: 0.2000\n",
      "Training Loss: 1.5726\n",
      "Validation - Dice Score: 0.4658\n",
      "Validation - Class Dice Scores: ['0.9650', '0.3045', '0.5428', '0.4658', '0.5503']\n",
      "Validation Loss: 1.6454\n",
      "NaN Count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 854/854 [6:17:47<00:00, 26.54s/img, accuracy=0.933, loss=1.51, loss (batch)=1.43, precision=0.245, recall=0.201]  \n",
      "validation: 100%|██████████| 934/934 [3:47:47<00:00, 14.63s/img, loss (batch)=1.7]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n",
      "Training - Accuracy: 0.9330, Precision: 0.2446, Recall: 0.2015\n",
      "Training Loss: 1.5104\n",
      "Validation - Dice Score: 0.4366\n",
      "Validation - Class Dice Scores: ['0.9298', '0.3095', '0.4948', '0.4401', '0.5021']\n",
      "Validation Loss: 1.6978\n",
      "NaN Count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 854/854 [6:26:10<00:00, 27.13s/img, accuracy=0.935, loss=1.44, loss (batch)=1.37, precision=0.29, recall=0.21]    \n",
      "validation: 100%|██████████| 934/934 [3:49:48<00:00, 14.76s/img, loss (batch)=2.01]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5\n",
      "Training - Accuracy: 0.9353, Precision: 0.2897, Recall: 0.2103\n",
      "Training Loss: 1.4445\n",
      "Validation - Dice Score: 0.4128\n",
      "Validation - Class Dice Scores: ['0.9518', '0.2208', '0.4989', '0.4807', '0.4507']\n",
      "Validation Loss: 2.0057\n",
      "NaN Count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 854/854 [6:28:29<00:00, 27.29s/img, accuracy=0.937, loss=1.4, loss (batch)=1.29, precision=0.298, recall=0.22]    \n",
      "validation: 100%|██████████| 934/934 [3:53:03<00:00, 14.97s/img, loss (batch)=3.02]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6\n",
      "Training - Accuracy: 0.9374, Precision: 0.2977, Recall: 0.2202\n",
      "Training Loss: 1.3995\n",
      "Validation - Dice Score: 0.4037\n",
      "Validation - Class Dice Scores: ['0.9235', '0.3299', '0.4401', '0.4304', '0.4143']\n",
      "Validation Loss: 3.0170\n",
      "NaN Count: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20:  13%|█▎        | 112/854 [53:06<5:51:48, 28.45s/img, accuracy=0.938, loss=1.37, loss (batch)=1.48, precision=0.298, recall=0.221]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 43\u001B[0m\n\u001B[0;32m     40\u001B[0m     logging\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mModel loaded from \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mload\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     42\u001B[0m net\u001B[38;5;241m.\u001B[39mto(device\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[1;32m---> 43\u001B[0m train_net(net\u001B[38;5;241m=\u001B[39mnet,\n\u001B[0;32m     44\u001B[0m               start_epoch \u001B[38;5;241m=\u001B[39m start_epoch,\n\u001B[0;32m     45\u001B[0m               epochs\u001B[38;5;241m=\u001B[39mepochs,\n\u001B[0;32m     46\u001B[0m               batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m     47\u001B[0m               learning_rate\u001B[38;5;241m=\u001B[39mlr,\n\u001B[0;32m     48\u001B[0m               device\u001B[38;5;241m=\u001B[39mdevice,\n\u001B[0;32m     49\u001B[0m               img_scale\u001B[38;5;241m=\u001B[39mscale,\n\u001B[0;32m     50\u001B[0m               train_percent \u001B[38;5;241m=\u001B[39m train,\n\u001B[0;32m     51\u001B[0m               val_percent\u001B[38;5;241m=\u001B[39mval,\n\u001B[0;32m     52\u001B[0m               save_checkpoint \u001B[38;5;241m=\u001B[39m save_checkpoint,\n\u001B[0;32m     53\u001B[0m               ampbool \u001B[38;5;241m=\u001B[39m ampbool,\n\u001B[0;32m     54\u001B[0m               traintype \u001B[38;5;241m=\u001B[39m traintype,\n\u001B[0;32m     55\u001B[0m               gradient_clipping\u001B[38;5;241m=\u001B[39mgradclip)\n",
      "Cell \u001B[1;32mIn[4], line 105\u001B[0m, in \u001B[0;36mtrain_net\u001B[1;34m(net, device, start_epoch, epochs, batch_size, learning_rate, train_percent, val_percent, save_checkpoint, img_scale, ampbool, traintype, gradient_clipping)\u001B[0m\n\u001B[0;32m     98\u001B[0m         loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m dice_loss(\n\u001B[0;32m     99\u001B[0m             F\u001B[38;5;241m.\u001B[39msoftmax(masks_pred, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mfloat()[:, \u001B[38;5;241m1\u001B[39m:, \u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m],\n\u001B[0;32m    100\u001B[0m             F\u001B[38;5;241m.\u001B[39mone_hot(post_masks, \u001B[38;5;241m5\u001B[39m)\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m)\u001B[38;5;241m.\u001B[39mfloat()[:, \u001B[38;5;241m1\u001B[39m:, \u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m],\n\u001B[0;32m    101\u001B[0m             multiclass\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    102\u001B[0m         )\n\u001B[0;32m    104\u001B[0m grad_scaler\u001B[38;5;241m.\u001B[39mscale(loss)\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m--> 105\u001B[0m grad_scaler\u001B[38;5;241m.\u001B[39mstep(optimizer)\n\u001B[0;32m    106\u001B[0m grad_scaler\u001B[38;5;241m.\u001B[39mupdate()\n\u001B[0;32m    108\u001B[0m \u001B[38;5;66;03m# Update metrics\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\xbdtwostep\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:454\u001B[0m, in \u001B[0;36mGradScaler.step\u001B[1;34m(self, optimizer, *args, **kwargs)\u001B[0m\n\u001B[0;32m    448\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39munscale_(optimizer)\n\u001B[0;32m    450\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m (\n\u001B[0;32m    451\u001B[0m     \u001B[38;5;28mlen\u001B[39m(optimizer_state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfound_inf_per_device\u001B[39m\u001B[38;5;124m\"\u001B[39m]) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    452\u001B[0m ), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo inf checks were recorded for this optimizer.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 454\u001B[0m retval \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_opt_step(optimizer, optimizer_state, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    456\u001B[0m optimizer_state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstage\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m OptState\u001B[38;5;241m.\u001B[39mSTEPPED\n\u001B[0;32m    458\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m retval\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\xbdtwostep\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:351\u001B[0m, in \u001B[0;36mGradScaler._maybe_opt_step\u001B[1;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001B[0m\n\u001B[0;32m    343\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_maybe_opt_step\u001B[39m(\n\u001B[0;32m    344\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    345\u001B[0m     optimizer: torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mOptimizer,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    348\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m    349\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Optional[\u001B[38;5;28mfloat\u001B[39m]:\n\u001B[0;32m    350\u001B[0m     retval: Optional[\u001B[38;5;28mfloat\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 351\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28msum\u001B[39m(v\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m optimizer_state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfound_inf_per_device\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues()):\n\u001B[0;32m    352\u001B[0m         retval \u001B[38;5;241m=\u001B[39m optimizer\u001B[38;5;241m.\u001B[39mstep(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    353\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m retval\n",
      "File \u001B[1;32m~\\AppData\\Local\\anaconda3\\envs\\xbdtwostep\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:351\u001B[0m, in \u001B[0;36m<genexpr>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    343\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_maybe_opt_step\u001B[39m(\n\u001B[0;32m    344\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    345\u001B[0m     optimizer: torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mOptimizer,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    348\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m    349\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Optional[\u001B[38;5;28mfloat\u001B[39m]:\n\u001B[0;32m    350\u001B[0m     retval: Optional[\u001B[38;5;28mfloat\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 351\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28msum\u001B[39m(v\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m optimizer_state[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfound_inf_per_device\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues()):\n\u001B[0;32m    352\u001B[0m         retval \u001B[38;5;241m=\u001B[39m optimizer\u001B[38;5;241m.\u001B[39mstep(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    353\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m retval\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5af383e1f6ec2ca1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
