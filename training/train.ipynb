{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-08T11:27:06.925777Z",
     "start_time": "2024-09-08T11:26:53.736943Z"
    }
   },
   "source": [
    "from model.my_models import SiameseUNetWithResnet50Encoder\n",
    "from model.evaluate import evaluate\n",
    "from utils.data_loading import SatelliteDataset\n",
    "from utils.dice_score import dice_loss\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.losses.focal import FocalLoss\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from torchvision import transforms\n",
    "from torchmetrics import ConfusionMatrix\n",
    "from torch import optim\n",
    "\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "in tensorboard see the architecture of model ",
   "id": "bcfde20f7107dd4a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T11:27:33.719296Z",
     "start_time": "2024-09-08T11:27:33.712428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img_home_path = \"C:/Users/liuyi/segment/ubdd/xbd/Dataset\"\n",
    "# img_home_path = \"C:/Users/liuyi/segment/ubdd/xbd/Dataset_test\"\n",
    "post_dir_img = img_home_path + \"/TierFull/Post/Image512/\"\n",
    "post_dir_mask = img_home_path + \"/TierFull/Post/Label512/\"\n",
    "pre_dir_img = img_home_path + \"/TierFull/Pre/Image512/\"\n",
    "pre_dir_mask = img_home_path + \"/TierFull/Pre/Label512/\"\n",
    "post_dir_val_img = img_home_path + \"/Validation/Post/Image512/\"\n",
    "post_dir_val_mask = img_home_path + \"/Validation/Post/Label512/\"\n",
    "pre_dir_val_img = img_home_path + \"/Validation/Pre/Image512/\"\n",
    "pre_dir_val_mask = img_home_path + \"/Validation/Pre/Label512/\"\n",
    "post_dir_test_img = img_home_path + \"/Test/Post/Image512/\"\n",
    "post_dir_test_mask = img_home_path + \"/Test/Post/Label512/\"\n",
    "pre_dir_test_img = img_home_path + \"/Test/Pre/Image512/\"\n",
    "pre_dir_test_mask = img_home_path + \"/Test/Pre/Label512/\"\n",
    "# post_dir_img = Path('.\\\\Dataset\\\\TierFull\\\\Post\\\\Image512\\\\')\n",
    "# post_dir_mask = Path('.\\\\Dataset\\\\TierFull\\\\Post\\\\Label512\\\\')\n",
    "# pre_dir_img = Path('.\\\\Dataset\\\\TierFull\\\\Pre\\\\Image512\\\\')\n",
    "# pre_dir_mask = Path('.\\\\Dataset\\\\TierFull\\\\Pre\\\\Label512\\\\')\n",
    "# post_dir_val_img = Path('.\\\\Dataset\\\\Validation\\\\Post\\\\Image512\\\\')\n",
    "# post_dir_val_mask = Path('.\\\\Dataset\\\\Validation\\\\Post\\\\Label512\\\\')\n",
    "# pre_dir_val_img = Path('.\\\\Dataset\\\\Validation\\\\Pre\\\\Image512\\\\')\n",
    "# pre_dir_val_mask = Path('.\\\\Dataset\\\\Validation\\\\Pre\\\\Label512\\\\')\n",
    "dir_checkpoint = Path('checkpoints/v_1.1_lr_10-4/')\n",
    "# dir_checkpoint = Path('checkpoints/v_1.0_lr_10-6/')"
   ],
   "id": "facb3659ae0b68",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T11:27:34.388951Z",
     "start_time": "2024-09-08T11:27:34.383383Z"
    }
   },
   "cell_type": "code",
   "source": [
    "closs = nn.CrossEntropyLoss()\n",
    "\n",
    "floss = FocalLoss(mode = 'multiclass',\n",
    "                alpha = None,\n",
    "                gamma = 2.0,\n",
    "                ignore_index = None,\n",
    "                reduction = \"mean\",\n",
    "                normalized = False,\n",
    "                reduced_threshold = None)"
   ],
   "id": "a1606a6cbf45f917",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T11:27:35.093459Z",
     "start_time": "2024-09-08T11:27:35.046165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import torchmetrics\n",
    "import numpy as np\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train_net(net,\n",
    "              device,\n",
    "              start_epoch: int = 1,\n",
    "              epochs: int = 5,\n",
    "              batch_size: int = 1,\n",
    "              learning_rate: float = 1e-5,\n",
    "              train_percent: float = 1,\n",
    "              val_percent: float = 1,\n",
    "              test_percent: float = 1,\n",
    "              save_checkpoint: bool = True,\n",
    "              img_scale: float = 0.5,\n",
    "              ampbool: bool = False,\n",
    "              traintype: str = 'post',\n",
    "              gradient_clipping: float = 1.0):\n",
    "    # 1. Create dataset\n",
    "    train = None\n",
    "    validate = None\n",
    "    test_set = None\n",
    "    try:\n",
    "        train = SatelliteDataset(pre_dir_img, pre_dir_mask, post_dir_img, post_dir_mask, 1, values=[[.8,1.5], True, True, True], probabilities=[0, 0, 0, 0])\n",
    "        validate = SatelliteDataset(pre_dir_val_img, pre_dir_val_mask, post_dir_val_img, post_dir_val_mask, 1, values=[[1, 1], False, False, False], probabilities=[0, 0, 0, 0])\n",
    "        test_set = SatelliteDataset(pre_dir_test_img, pre_dir_test_mask, post_dir_test_img, post_dir_test_mask, 1, values=[[1, 1], False, False, False], probabilities=[0, 0, 0, 0])\n",
    "    except (AssertionError, RuntimeError):\n",
    "        print('Error creating datasets')\n",
    "\n",
    "    loader_args = dict(batch_size=batch_size, num_workers=1, pin_memory=True)\n",
    "    \n",
    "    # 2. Split into train / validation partitions\n",
    "    n_train = int(len(train) * train_percent)\n",
    "    n_train_none = int(len(train) - n_train)\n",
    "    n_val = int(len(validate) * val_percent)\n",
    "    n_val_none = int(len(validate) - n_val)\n",
    "    n_test = int(len(test_set) * test_percent)\n",
    "    n_test_none = int(len(test_set) - n_test)\n",
    "\n",
    "    train_set, train_val_none_set = random_split(train, [n_train, n_train_none], generator=torch.Generator().manual_seed(0))\n",
    "    train_loader = DataLoader(train_set, shuffle=True, **loader_args)\n",
    "\n",
    "    val_set, val_none_set = random_split(validate, [n_val, n_val_none], generator=torch.Generator().manual_seed(0))\n",
    "    val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)\n",
    "    \n",
    "    test_set, test_none_set = random_split(test_set, [n_test, n_test_none], generator=torch.Generator().manual_seed(0))\n",
    "    test_loader = DataLoader(test_set, shuffle=False, drop_last=True, **loader_args)\n",
    "\n",
    "    # 4. Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n",
    "    optimizer = optim.RMSprop(net.parameters(), lr=learning_rate, weight_decay=1e-6, momentum=0.9, foreach=True)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[3,6,9,12,15,18,19,20,33,47,50,60,70,90,110,130,150,170,180,190], gamma=0.5)\n",
    "    grad_scaler = torch.amp.GradScaler('cuda', enabled=ampbool)\n",
    "    criterion = closs\n",
    "    \n",
    "    # 5. Initialize torchmetrics metrics\n",
    "    train_accuracy = torchmetrics.Accuracy(task='multiclass', num_classes=5, validate_args=False).to(device)\n",
    "    train_precision = torchmetrics.Precision(task='multiclass', num_classes=5, average='macro', validate_args=False).to(device)\n",
    "    train_recall = torchmetrics.Recall(task='multiclass', num_classes=5, average='macro', validate_args=False).to(device)\n",
    "    \n",
    "    #TODO: 是否加入早停\n",
    "    #early_stopping = EarlyStopping(patience=3, verbose=True)\n",
    "\n",
    "    # 6. Begin training\n",
    "    for epoch in range(start_epoch, start_epoch + epochs):\n",
    "        net.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_steps = 0\n",
    "        nancount = 0\n",
    "        with tqdm(total=n_train, desc=f'Epoch {epoch}/{epochs}', unit='img') as pbar:\n",
    "            for batch in train_loader:\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                preimage, postimage, post_masks, pre_masks = batch['preimage'], batch['postimage'], batch['postmask'], batch['premask']\n",
    "\n",
    "                preimage = preimage.to(device=device, dtype=torch.float32)\n",
    "                postimage = postimage.to(device=device, dtype=torch.float32)\n",
    "                post_masks = post_masks.to(device=device, dtype=torch.long)\n",
    "                pre_masks = pre_masks.to(device=device, dtype=torch.long)\n",
    "                \n",
    "                with torch.amp.autocast('cuda', enabled=ampbool):\n",
    "                    masks_pred = None\n",
    "                    if traintype == 'both':\n",
    "                        masks_pred = net(preimage, postimage)\n",
    "                        loss = criterion(masks_pred, post_masks)\n",
    "                        loss += dice_loss(\n",
    "                            F.softmax(masks_pred, dim=1).float()[:, 1:, ...],\n",
    "                            F.one_hot(post_masks, 5).permute(0, 3, 1, 2).float()[:, 1:, ...],\n",
    "                            multiclass=True\n",
    "                        )\n",
    "                    elif traintype == 'pre':\n",
    "                        masks_pred = net(preimage)\n",
    "                        loss = criterion(masks_pred, pre_masks)\n",
    "                        loss += dice_loss(\n",
    "                            F.softmax(masks_pred, dim=1).float(),\n",
    "                            F.one_hot(pre_masks, 2).permute(0, 3, 1, 2).float(),\n",
    "                            multiclass=True\n",
    "                        )\n",
    "                    elif traintype == 'post':\n",
    "                        masks_pred = net(postimage)\n",
    "                        loss = criterion(masks_pred, post_masks)\n",
    "                        loss += dice_loss(\n",
    "                            F.softmax(masks_pred, dim=1).float()[:, 1:, ...],\n",
    "                            F.one_hot(post_masks, 5).permute(0, 3, 1, 2).float()[:, 1:, ...],\n",
    "                            multiclass=True\n",
    "                        )\n",
    "\n",
    "                grad_scaler.scale(loss).backward()\n",
    "                grad_scaler.step(optimizer)\n",
    "                grad_scaler.update()\n",
    "                \n",
    "                # Update metrics\n",
    "                train_accuracy.update(masks_pred, post_masks)\n",
    "                train_precision.update(masks_pred, post_masks)\n",
    "                train_recall.update(masks_pred, post_masks)\n",
    "                \n",
    "                pbar.update(postimage.shape[0])\n",
    "                epoch_steps += 1 #已经处理的批次数\n",
    "                \n",
    "                if math.isnan(loss.item()):\n",
    "                    epoch_loss += 0\n",
    "                    nancount += 1\n",
    "                else:\n",
    "                    epoch_loss += loss.item()   \n",
    "                    \n",
    "                # if epoch_steps == 1 or epoch_steps % max(1, len(train_loader) // 10) == 0:\n",
    "                pbar.set_postfix(**{\n",
    "                    'loss (batch)': float(loss.item()),\n",
    "                    'loss': float(epoch_loss / epoch_steps),\n",
    "                    'accuracy': float(train_accuracy.compute().item()),\n",
    "                    'precision': float(train_precision.compute().item()),\n",
    "                    'recall': float(train_recall.compute().item())\n",
    "                })\n",
    "                \n",
    "        # 计算最终的训练指标\n",
    "        train_acc = train_accuracy.compute()\n",
    "        train_prec = train_precision.compute()\n",
    "        train_rec = train_recall.compute()\n",
    "        train_loss = epoch_loss / len(train_loader)\n",
    "        \n",
    "        # 使用现有的evaluate函数进行验证\n",
    "        val_score, val_class_scores, val_loss = evaluate(net, dataloader=val_loader, device=device, ampbool=ampbool, traintype=traintype)\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f'Epoch {epoch}')\n",
    "        print(f'Training - Accuracy: {train_acc:.4f}, Precision: {train_prec:.4f}, Recall: {train_rec:.4f}')\n",
    "        print(f'Training Loss: {train_loss:.4f}')\n",
    "        print(f'Validation - Dice Score: {val_score:.4f}')\n",
    "        print(f'Validation - Class Dice Scores: {[f\"{score:.4f}\" for score in val_class_scores]}')\n",
    "        print(f'Validation Loss: {val_loss:.4f}')\n",
    "        print(f'NaN Count: {nancount}')\n",
    "\n",
    "        if save_checkpoint:\n",
    "            Path(dir_checkpoint).mkdir(parents=True, exist_ok=True)\n",
    "            torch.save(net.state_dict(), str(dir_checkpoint / f'branch12checkpoint_epoch_{epoch}.pth'))\n",
    "            logging.info(f'Checkpoint {epoch} saved!')\n",
    "            \n",
    "    # Final evaluation on test set\n",
    "    test_score, test_class_scores, test_loss = evaluate(net, test_loader, device, ampbool, traintype)\n",
    "    print('Final Test Results:')\n",
    "    print(f'Test - Dice Score: {test_score:.4f}')\n",
    "    print(f'Test - Class Dice Scores: {[f\"{score:.4f}\" for score in test_class_scores]}')\n",
    "    print(f'Test Loss: {test_loss:.4f}')\n",
    "    # \n",
    "    # return train_loss, val_loss, test_loss\n"
   ],
   "id": "cf171a33a2c07a5a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T11:27:35.650666Z",
     "start_time": "2024-09-08T11:27:35.643565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classes = 5\n",
    "bilinear = True\n",
    "loadstate = False\n",
    "# loadstate = True\n",
    "load = './checkpoints/Vgg19SiamConc/checkpoint_epoch12.pth'\n",
    "start_epoch = 0\n",
    "# start_epoch = 13\n",
    "epochs = 20\n",
    "batch_size = 1\n",
    "lr = 1e-4\n",
    "# lr = 1e-6\n",
    "scale = 1\n",
    "train = 1\n",
    "# train =0.15259598603*2\n",
    "val = 1\n",
    "test = 1\n",
    "ampbool = True\n",
    "save_checkpoint = True\n",
    "traintype = 'both'\n",
    "gradclip = 1.0"
   ],
   "id": "abbc24f28ad0b659",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T11:27:36.037059Z",
     "start_time": "2024-09-08T11:27:36.030718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def confusionmatrix(pred,true):\n",
    "    result = np.zeros((5,5))\n",
    "    for i in range(true.shape[1]):\n",
    "        for j in range(true.shape[2]):\n",
    "            result[true[0][i][j]][pred[0][i][j]] +=1\n",
    "    return result"
   ],
   "id": "7e9ed12de022451e",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T11:27:36.463463Z",
     "start_time": "2024-09-08T11:27:36.443960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def modelconfusionmatrix(filepath,net,train_percent,val_percent):\n",
    "    device = 'cuda'\n",
    "    net.load_state_dict(torch.load(filepath, map_location=device))\n",
    "    net.to(device=device)\n",
    "    net.eval() # 评估模式\n",
    "    \n",
    "    try:\n",
    "        train = SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, 1, values =  [[.8,1.5], True, True,True], probabilities = [0,0,0,0])\n",
    "        validate = SatelliteDataset(pre_dir_val_img, pre_dir_val_mask,post_dir_val_img, post_dir_val_mask, 1, values =  [[1,1], False, False, False], probabilities = [0,0,0,0])\n",
    "        # train = SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, 1, values =  [[.8,1.5], True, True,True], probabilities = [0,0,0,0],increase = 0 ,mask_suffix = '.png',normalizemodel = 'vgg19')\n",
    "        # validate = SatelliteDataset(pre_dir_val_img, pre_dir_val_mask,post_dir_val_img, post_dir_val_mask, 1, values =  [[1,1], False, False, False], probabilities = [0,0,0,0],increase = 0,mask_suffix = '.png', normalizemodel = 'vgg19')\n",
    "    except (AssertionError, RuntimeError):\n",
    "        print('error')\n",
    "\n",
    "    loader_args = dict(batch_size=1, num_workers=1, pin_memory=True)        \n",
    "        \n",
    "    # 2. Split into train / validation partitions\n",
    "    n_train = int(len(train) * train_percent)\n",
    "    n_train_none = int(len(train) - n_train)\n",
    "    n_val = int(len(validate) * val_percent)\n",
    "    n_val_none = int(len(validate) - n_val)\n",
    "\n",
    "    train_set, train_val_none_set = random_split(train, [n_train, n_train_none], generator=torch.Generator().manual_seed(0))\n",
    "    \n",
    "    train_loader = DataLoader(train_set, shuffle=True, **loader_args)    \n",
    "\n",
    "    val_set, val_none_set = random_split(validate, [n_val, n_val_none], generator=torch.Generator().manual_seed(0))    \n",
    "\n",
    "    val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args) \n",
    "    resulttrain = torch.zeros(5,5).to(device)\n",
    "    resultval = torch.zeros(5,5).to(device)\n",
    "\n",
    "    num_val_batches = len(val_loader)\n",
    "    num_train_batches = len(train_loader)\n",
    "    confmat = ConfusionMatrix(task=\"multiclass\", num_classes=5).to(device)\n",
    "\n",
    "    with tqdm(total=num_train_batches, desc='train', unit='img') as pbar:\n",
    "        for batch in train_loader:\n",
    "            preimage, postimage, true_masks = batch['preimage'], batch['postimage'], batch['postmask']\n",
    "            # preimage, postimage, true_masks = batch['preimage'], batch['image'], batch['mask']\n",
    "            preimage = preimage.to(device=device, dtype=torch.float32)\n",
    "            postimage = postimage.to(device=device, dtype=torch.float32)\n",
    "            true_masks = true_masks.to(device=device, dtype=torch.long)\n",
    "            mask_true = F.one_hot(true_masks, 5).permute(0,3, 1, 2).float()\n",
    "            with torch.amp.autocast('cuda', enabled = True):\n",
    "                # predict the mask\n",
    "                mask_pred = net(preimage,postimage)\n",
    "                # convert to one-hot format\n",
    "                pred = F.softmax(mask_pred, dim=1).int().argmax(-3)\n",
    "                true = F.one_hot(true_masks, 5).int().permute(0, 3, 1, 2).argmax(-3)\n",
    "                resulttrain += confmat(pred,true)\n",
    "            pbar.update(postimage.shape[0])\n",
    "    print(resulttrain)\n",
    "    with tqdm(total=num_val_batches, desc='validation', unit='img') as pbar:\n",
    "        for batch in val_loader:\n",
    "            preimage, postimage, true_masks = batch['preimage'], batch['postimage'], batch['postmask']\n",
    "            preimage = preimage.to(device=device, dtype=torch.float32)\n",
    "            postimage = postimage.to(device=device, dtype=torch.float32)\n",
    "            true_masks = true_masks.to(device=device, dtype=torch.long)\n",
    "            mask_true = F.one_hot(true_masks, 5).permute(0,3, 1, 2).float()\n",
    "            with torch.cuda.amp.autocast(enabled = True):\n",
    "                # predict the mask\n",
    "                mask_pred = net(preimage,postimage)\n",
    "                # convert to one-hot format\n",
    "                pred = F.softmax(mask_pred, dim=1).int().argmax(-3)\n",
    "                true = F.one_hot(true_masks, 5).int().permute(0, 3, 1, 2).argmax(-3)\n",
    "                resultval += confmat(pred,true)\n",
    "            pbar.update(postimage.shape[0])\n",
    "    print(resultval)\n",
    "    net.train()\n",
    "\n",
    "    # Fixes a potential division by zero error\n",
    "    if num_val_batches == 0:\n",
    "        return resulttrain,resultval\n",
    "    return resulttrain,resultval"
   ],
   "id": "b948416bc246378b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T11:27:36.903194Z",
     "start_time": "2024-09-08T11:27:36.890981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def EvaluateFolder(folderpath,net,train_percent,val_percent):\n",
    "    in_files = [folderpath + s for s in os.listdir(folderpath)]\n",
    "    try:\n",
    "        train = SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, 1, values =  [[.8,1.5], True, True,True], probabilities = [0,0,0,0])\n",
    "        # train = SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, 1, values =  [[.8,1.5], True, True,True], probabilities = [0,0,0,0],increase = 0 ,mask_suffix = '.png',normalizemodel = 'vgg19')\n",
    "        validate = SatelliteDataset(pre_dir_val_img, pre_dir_val_mask,post_dir_val_img, post_dir_val_mask, 1, values =  [[1,1], False, False, False], probabilities = [0,0,0,0]) \n",
    "        # validate = SatelliteDataset(pre_dir_val_img, pre_dir_val_mask,post_dir_val_img, post_dir_val_mask, 1, values =  [[1,1], False, False, False], probabilities = [0,0,0,0],increase = 0,mask_suffix = '.png', normalizemodel = 'vgg19')\n",
    "    except (AssertionError, RuntimeError):\n",
    "        print('error')\n",
    "\n",
    "    loader_args = dict(batch_size=1, num_workers=1, pin_memory=True)        \n",
    "        \n",
    "    # 2. Split into train / validation partitions\n",
    "    n_train = int(len(train) * train_percent)\n",
    "    n_train_none = int(len(train) - n_train)\n",
    "    n_val = int(len(validate) * val_percent)\n",
    "    n_val_none = int(len(validate) - n_val)\n",
    "\n",
    "    train_set, train_val_none_set = random_split(train, [n_train, n_train_none], generator=torch.Generator().manual_seed(0))\n",
    "    \n",
    "    train_loader = DataLoader(train_set, shuffle=True, **loader_args)    \n",
    "\n",
    "    val_set, val_none_set = random_split(validate, [n_val, n_val_none], generator=torch.Generator().manual_seed(0))    \n",
    "\n",
    "    val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    loader_args = dict(batch_size=1, num_workers=1, pin_memory=True)        \n",
    "    \n",
    "    for i in in_files:\n",
    "        net.load_state_dict(torch.load(i, map_location=device))\n",
    "        net.to(device=device)\n",
    "        val_score, val_classes,val_loss = evaluate(net,dataloader = val_loader,device = device,ampbool = True,traintype = 'both')\n",
    "        train_score, train_classes,train_loss = evaluate(net,dataloader = train_loader,device = device,ampbool = True,traintype = 'both')\n",
    "        print('Train: ' + i)\n",
    "        print(train_score)\n",
    "        print(train_classes)\n",
    "        print(train_loss)\n",
    "        print('Validation: ' + i)\n",
    "        print(val_score)\n",
    "        print(val_classes)\n",
    "        print(val_loss)"
   ],
   "id": "68343e76dce750c1",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T11:27:40.659909Z",
     "start_time": "2024-09-08T11:27:38.064221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# net = SiamUNetConCVgg19()\n",
    "net = SiameseUNetWithResnet50Encoder()"
   ],
   "id": "96d2349ef657b1a4",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T11:27:41.944068Z",
     "start_time": "2024-09-08T11:27:40.676926Z"
    }
   },
   "cell_type": "code",
   "source": "EvaluateFolder('./checkpoints/Final/',net,train,val)",
   "id": "6693f5575c23882e",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: './checkpoints/Final/'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m EvaluateFolder(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./checkpoints/Final/\u001B[39m\u001B[38;5;124m'\u001B[39m,net,train,val)\n",
      "Cell \u001B[1;32mIn[9], line 2\u001B[0m, in \u001B[0;36mEvaluateFolder\u001B[1;34m(folderpath, net, train_percent, val_percent)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mEvaluateFolder\u001B[39m(folderpath,net,train_percent,val_percent):\n\u001B[1;32m----> 2\u001B[0m     in_files \u001B[38;5;241m=\u001B[39m [folderpath \u001B[38;5;241m+\u001B[39m s \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m os\u001B[38;5;241m.\u001B[39mlistdir(folderpath)]\n\u001B[0;32m      3\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m      4\u001B[0m         train \u001B[38;5;241m=\u001B[39m SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, \u001B[38;5;241m1\u001B[39m, values \u001B[38;5;241m=\u001B[39m  [[\u001B[38;5;241m.8\u001B[39m,\u001B[38;5;241m1.5\u001B[39m], \u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;28;01mTrue\u001B[39;00m,\u001B[38;5;28;01mTrue\u001B[39;00m], probabilities \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m0\u001B[39m])\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 3] 系统找不到指定的路径。: './checkpoints/Final/'"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T11:27:44.002548Z",
     "start_time": "2024-09-08T11:27:43.992655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])"
   ],
   "id": "65f38a4fc06055b2",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T11:27:45.033331Z",
     "start_time": "2024-09-08T11:27:45.020497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mem_params = sum([param.nelement()*param.element_size() for param in net.parameters()])\n",
    "mem_bufs = sum([buf.nelement()*buf.element_size() for buf in net.buffers()])\n",
    "mem = mem_params + mem_bufs\n",
    "mem"
   ],
   "id": "cc9435c0dde00a3f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "553700636"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-09-08T11:27:45.919734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "    #net = SiamUNetDiff()\n",
    "    #net = SiamUNetConC()\n",
    "    #net = SiameseUNetWithResnet50Encoder()\n",
    "    #net = SiamUnet_diff_Full(3,5)\n",
    "    #net = UNetWithResnet50Encoder(5,'custom','./checkpoints/Resnet50ContrastiveWeight/checkpoint_epoch0.pth')\n",
    "    #net = UNet(out_classes=classes, up_sample_mode='conv_transpose',batch_norm=False)\n",
    "    #net = SiameseUNet(n_channels=3, n_classes = classes, bilinear=bilinear)\n",
    "    #net = UNetVgg19V2(out_classes=classes, up_sample_mode='conv_transpose')\n",
    "    #net = vgg19bn_unet(5,True)\n",
    "    #net = vgg19nobn_unet(5,True)\n",
    "    #net = vgg19nobn_unetdouble(5,True)\n",
    "    #net = VGGUnet19nobnspace(out_channels = 5, pretrained = True)\n",
    "    #net = SiamUNetCombVgg19()\n",
    "    ### 之前是用这个 net = SiamUNetConCVgg19()\n",
    "    #net = resnet_unet()\n",
    "    #net = VGG16Unet(out_channels = 5)\n",
    "    #net = resnet_siamunet()\n",
    "    #net = SiamUNetDiffVgg19()\n",
    "    #net = SiamUNetFullConCVgg19()\n",
    "    #net = SiamUNetConCResnet50(True,5)\n",
    "    #net = UNETResnet50(True,2)\n",
    "    '''net = smp.Unet(\n",
    "        encoder_name='resnext101_32x8d',\n",
    "        encoder_depth=5,\n",
    "        encoder_weights='imagenet',\n",
    "        decoder_use_batchnorm=False,\n",
    "        decoder_channels=(1024,512,256,128, 64),\n",
    "        decoder_attention_type=None,\n",
    "        in_channels=3,\n",
    "        classes=5,\n",
    "        activation=None,\n",
    "        aux_params=None\n",
    "    )\n",
    "    '''\n",
    "    if loadstate:\n",
    "        net.load_state_dict(torch.load(load, map_location=device))\n",
    "        logging.info(f'Model loaded from {load}')\n",
    "\n",
    "    net.to(device=device)\n",
    "    train_net(net=net,\n",
    "                  start_epoch = start_epoch,\n",
    "                  epochs=epochs,\n",
    "                  batch_size=batch_size,\n",
    "                  learning_rate=lr,\n",
    "                  device=device,\n",
    "                  img_scale=scale,\n",
    "                  train_percent = train,\n",
    "                  val_percent=val,\n",
    "                  save_checkpoint = save_checkpoint,\n",
    "                  ampbool = ampbool,\n",
    "                  traintype = traintype,\n",
    "                  gradient_clipping=gradclip)"
   ],
   "id": "a1fb80075cdc127b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/20:   0%|          | 7/2800 [01:55<11:50:15, 15.26s/img, accuracy=0.923, loss=2.08, loss (batch)=1.79, precision=0.211, recall=0.202]"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
