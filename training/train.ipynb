{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-14T13:09:27.745451Z",
     "start_time": "2024-09-14T13:09:27.742217Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from model.my_models import SiameseUNetWithResnet50Encoder\n",
    "from model.evaluate import evaluate\n",
    "from utils.data_loading import SatelliteDataset\n",
    "from utils.dice_score import dice_loss\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from segmentation_models_pytorch.losses.focal import FocalLoss\n",
    "from torchmetrics import ConfusionMatrix\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfde20f7107dd4a",
   "metadata": {},
   "source": [
    "in tensorboard see the architecture of model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "facb3659ae0b68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T11:27:33.719296Z",
     "start_time": "2024-09-08T11:27:33.712428Z"
    }
   },
   "outputs": [],
   "source": [
    "img_home_path = \"C:/Users/xiao/peng/xbd/Dataset\"\n",
    "# img_home_path = \"C:/Users/liuyi/segment/ubdd/xbd/Dataset_test\"\n",
    "post_dir_img = img_home_path + \"/TierFull/Post/Image512/\"\n",
    "post_dir_mask = img_home_path + \"/TierFull/Post/Label512/\"\n",
    "pre_dir_img = img_home_path + \"/TierFull/Pre/Image512/\"\n",
    "pre_dir_mask = img_home_path + \"/TierFull/Pre/Label512/\"\n",
    "post_dir_val_img = img_home_path + \"/Validation/Post/Image512/\"\n",
    "post_dir_val_mask = img_home_path + \"/Validation/Post/Label512/\"\n",
    "pre_dir_val_img = img_home_path + \"/Validation/Pre/Image512/\"\n",
    "pre_dir_val_mask = img_home_path + \"/Validation/Pre/Label512/\"\n",
    "post_dir_test_img = img_home_path + \"/Test/Post/Image512/\"\n",
    "post_dir_test_mask = img_home_path + \"/Test/Post/Label512/\"\n",
    "pre_dir_test_img = img_home_path + \"/Test/Pre/Image512/\"\n",
    "pre_dir_test_mask = img_home_path + \"/Test/Pre/Label512/\"\n",
    "# post_dir_img = Path('.\\\\Dataset\\\\TierFull\\\\Post\\\\Image512\\\\')\n",
    "# post_dir_mask = Path('.\\\\Dataset\\\\TierFull\\\\Post\\\\Label512\\\\')\n",
    "# pre_dir_img = Path('.\\\\Dataset\\\\TierFull\\\\Pre\\\\Image512\\\\')\n",
    "# pre_dir_mask = Path('.\\\\Dataset\\\\TierFull\\\\Pre\\\\Label512\\\\')\n",
    "# post_dir_val_img = Path('.\\\\Dataset\\\\Validation\\\\Post\\\\Image512\\\\')\n",
    "# post_dir_val_mask = Path('.\\\\Dataset\\\\Validation\\\\Post\\\\Label512\\\\')\n",
    "# pre_dir_val_img = Path('.\\\\Dataset\\\\Validation\\\\Pre\\\\Image512\\\\')\n",
    "# pre_dir_val_mask = Path('.\\\\Dataset\\\\Validation\\\\Pre\\\\Label512\\\\')\n",
    "dir_checkpoint = Path('checkpoints/v_1.2_lr_2e-4/')\n",
    "# dir_checkpoint = Path('checkpoints/v_1.0_lr_10-6/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1606a6cbf45f917",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T11:27:34.388951Z",
     "start_time": "2024-09-08T11:27:34.383383Z"
    }
   },
   "outputs": [],
   "source": [
    "closs = nn.CrossEntropyLoss()\n",
    "\n",
    "floss = FocalLoss(mode = 'multiclass',\n",
    "                alpha = None,\n",
    "                gamma = 2.0,\n",
    "                ignore_index = None,\n",
    "                reduction = \"mean\",\n",
    "                normalized = False,\n",
    "                reduced_threshold = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf171a33a2c07a5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T11:27:35.093459Z",
     "start_time": "2024-09-08T11:27:35.046165Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchmetrics\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from clearml import Task\n",
    "\n",
    "def train_net(net,\n",
    "               device,\n",
    "              start_epoch: int = 1,\n",
    "              epochs: int = 5,\n",
    "              batch_size: int = 1,\n",
    "              learning_rate: float = 1e-5,\n",
    "              train_percent: float = 1,\n",
    "              val_percent: float = 1,\n",
    "              test_percent: float = 1,\n",
    "              save_checkpoint: bool = True,\n",
    "              img_scale: float = 0.5,\n",
    "              ampbool: bool = False,\n",
    "              traintype: str = 'both',\n",
    "              gradient_clipping: float = 1.0):\n",
    "\n",
    "    # 1. Create dataset\n",
    "    train = None\n",
    "    validate = None\n",
    "    test_set = None\n",
    "    try:\n",
    "        train = SatelliteDataset(pre_dir_img, pre_dir_mask, post_dir_img, post_dir_mask, 1, values=[[.8,1.5], True, True, True], probabilities=[0, 0, 0, 0])\n",
    "        validate = SatelliteDataset(pre_dir_val_img, pre_dir_val_mask, post_dir_val_img, post_dir_val_mask, 1, values=[[1, 1], False, False, False], probabilities=[0, 0, 0, 0])\n",
    "        test_set = SatelliteDataset(pre_dir_test_img, pre_dir_test_mask, post_dir_test_img, post_dir_test_mask, 1, values=[[1, 1], False, False, False], probabilities=[0, 0, 0, 0])\n",
    "    except (AssertionError, RuntimeError):\n",
    "        print('Error creating datasets')\n",
    "\n",
    "    loader_args = dict(batch_size=batch_size, num_workers=1, pin_memory=True)\n",
    "    \n",
    "    # 2. Split into train / validation partitions\n",
    "    n_train = int(len(train) * train_percent)\n",
    "    n_train_none = int(len(train) - n_train)\n",
    "    n_val = int(len(validate) * val_percent)\n",
    "    n_val_none = int(len(validate) - n_val)\n",
    "    n_test = int(len(test_set) * test_percent)\n",
    "    n_test_none = int(len(test_set) - n_test)\n",
    "\n",
    "    train_set, train_val_none_set = random_split(train, [n_train, n_train_none], generator=torch.Generator().manual_seed(0))\n",
    "    train_loader = DataLoader(train_set, shuffle=True, **loader_args)\n",
    "\n",
    "    val_set, val_none_set = random_split(validate, [n_val, n_val_none], generator=torch.Generator().manual_seed(0))\n",
    "    val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)\n",
    "    \n",
    "    test_set, test_none_set = random_split(test_set, [n_test, n_test_none], generator=torch.Generator().manual_seed(0))\n",
    "    test_loader = DataLoader(test_set, shuffle=False, drop_last=True, **loader_args)\n",
    "\n",
    "    # 4. Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n",
    "    optimizer = optim.RMSprop(net.parameters(), lr=learning_rate, weight_decay=1e-6, momentum=0.9, foreach=True)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[5,11,17,23,29,33], gamma=0.5)\n",
    "\n",
    "    # scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[3,6,9,12,15,18,19,20,33,47,50,60,70,90,110,130,150,170,180,190], gamma=0.5)\n",
    "    grad_scaler = torch.amp.GradScaler('cuda', enabled=ampbool)\n",
    "    criterion = closs\n",
    "    \n",
    "    # 5. Initialize torchmetrics metrics\n",
    "    train_accuracy = torchmetrics.Accuracy(task='multiclass', num_classes=5, validate_args=False).to(device)\n",
    "    train_precision = torchmetrics.Precision(task='multiclass', num_classes=5, average='macro', validate_args=False).to(device)\n",
    "    train_recall = torchmetrics.Recall(task='multiclass', num_classes=5, average='macro', validate_args=False).to(device)\n",
    "    \n",
    "    #TODO: 是否加入早停\n",
    "    #early_stopping = EarlyStopping(patience=3, verbose=True)\n",
    "\n",
    "    # 5.1. 获取 ClearML 任务对象\n",
    "    task = Task.current_task()\n",
    "    if task is None:\n",
    "        print(\"Warning: No active ClearML task. Metrics will not be logged.\")\n",
    "\n",
    "    # 6. Begin training\n",
    "    for epoch in range(start_epoch, start_epoch + epochs):\n",
    "        net.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_steps = 0\n",
    "        nancount = 0\n",
    "        with tqdm(total=n_train, desc=f'Epoch {epoch}/{epochs}', unit='img') as pbar:\n",
    "            for batch in train_loader:\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                preimage, postimage, post_masks, pre_masks = batch['preimage'], batch['postimage'], batch['postmask'], batch['premask']\n",
    "\n",
    "                preimage = preimage.to(device=device, dtype=torch.float32)\n",
    "                postimage = postimage.to(device=device, dtype=torch.float32)\n",
    "                post_masks = post_masks.to(device=device, dtype=torch.long)\n",
    "                pre_masks = pre_masks.to(device=device, dtype=torch.long)\n",
    "                \n",
    "                with torch.amp.autocast('cuda', enabled=ampbool):\n",
    "                    masks_pred = None\n",
    "                    if traintype == 'both':\n",
    "                        masks_pred = net(preimage, postimage)\n",
    "                        loss = criterion(masks_pred, post_masks)\n",
    "                        loss += dice_loss(\n",
    "                            F.softmax(masks_pred, dim=1).float()[:, 1:, ...],\n",
    "                            F.one_hot(post_masks, 5).permute(0, 3, 1, 2).float()[:, 1:, ...],\n",
    "                            multiclass=True\n",
    "                        )\n",
    "                    elif traintype == 'pre':\n",
    "                        masks_pred = net(preimage)\n",
    "                        loss = criterion(masks_pred, pre_masks)\n",
    "                        loss += dice_loss(\n",
    "                            F.softmax(masks_pred, dim=1).float(),\n",
    "                            F.one_hot(pre_masks, 2).permute(0, 3, 1, 2).float(),\n",
    "                            multiclass=True\n",
    "                        )\n",
    "                    elif traintype == 'post':\n",
    "                        masks_pred = net(postimage)\n",
    "                        loss = criterion(masks_pred, post_masks)\n",
    "                        loss += dice_loss(\n",
    "                            F.softmax(masks_pred, dim=1).float()[:, 1:, ...],\n",
    "                            F.one_hot(post_masks, 5).permute(0, 3, 1, 2).float()[:, 1:, ...],\n",
    "                            multiclass=True\n",
    "                        )\n",
    "\n",
    "                grad_scaler.scale(loss).backward()\n",
    "                grad_scaler.step(optimizer)\n",
    "                grad_scaler.update()\n",
    "                \n",
    "                # Update metrics\n",
    "                train_accuracy.update(masks_pred, post_masks)\n",
    "                train_precision.update(masks_pred, post_masks)\n",
    "                train_recall.update(masks_pred, post_masks)\n",
    "                \n",
    "                pbar.update(postimage.shape[0])\n",
    "                epoch_steps += 1 #已经处理的批次数\n",
    "                \n",
    "                if math.isnan(loss.item()):\n",
    "                    epoch_loss += 0\n",
    "                    nancount += 1\n",
    "                else:\n",
    "                    epoch_loss += loss.item()   \n",
    "                    \n",
    "                # if epoch_steps == 1 or epoch_steps % max(1, len(train_loader) // 10) == 0:\n",
    "                pbar.set_postfix(**{\n",
    "                    'loss (batch)': float(loss.item()),\n",
    "                    'loss': float(epoch_loss / epoch_steps),\n",
    "                    'accuracy': float(train_accuracy.compute().item()),\n",
    "                    'precision': float(train_precision.compute().item()),\n",
    "                    'recall': float(train_recall.compute().item())\n",
    "                })\n",
    "                \n",
    "        # 计算最终的训练指标\n",
    "        train_acc = train_accuracy.compute()\n",
    "        train_prec = train_precision.compute()\n",
    "        train_rec = train_recall.compute()\n",
    "        train_loss = epoch_loss / len(train_loader)\n",
    "        \n",
    "        # 使用现有的evaluate函数进行验证\n",
    "        val_score, val_class_scores, val_loss = evaluate(net, dataloader=val_loader, device=device, ampbool=ampbool, traintype=traintype)\n",
    "        scheduler.step()\n",
    "        \n",
    "        # 打印训练和验证结果\n",
    "        print(f'Epoch {epoch}')\n",
    "        print(f'Training - Accuracy: {train_acc:.4f}, Precision: {train_prec:.4f}, Recall: {train_rec:.4f}')\n",
    "        print(f'Training Loss: {train_loss:.4f}')\n",
    "        print(f'Validation - Dice Score: {val_score:.4f}')\n",
    "        print(f'Validation - Class Dice Scores: {[f\"{score:.4f}\" for score in val_class_scores]}')\n",
    "        print(f'Validation Loss: {val_loss:.4f}')\n",
    "        print(f'NaN Count: {nancount}')\n",
    "        \n",
    "        if save_checkpoint:\n",
    "            Path(dir_checkpoint).mkdir(parents=True, exist_ok=True)\n",
    "            checkpoint_path = str(dir_checkpoint / f'branch12checkpoint_epoch_{epoch}.pth')\n",
    "            torch.save(net.state_dict(), checkpoint_path)\n",
    "            logging.info(f'Checkpoint {epoch} saved!')\n",
    "            if task:\n",
    "                task.upload_artifact(f\"checkpoint_epoch_{epoch}\", checkpoint_path)\n",
    "                # 记录指标到 ClearML\n",
    "        if task:\n",
    "            task.get_logger().report_scalar(\"Accuracy\", \"train\", value=train_acc, iteration=epoch)\n",
    "            task.get_logger().report_scalar(\"Precision\", \"train\", value=train_prec, iteration=epoch)\n",
    "            task.get_logger().report_scalar(\"Recall\", \"train\", value=train_rec, iteration=epoch)\n",
    "            task.get_logger().report_scalar(\"Loss\", \"train\", value=train_loss, iteration=epoch)\n",
    "            task.get_logger().report_scalar(\"Dice Score\", \"validation\", value=val_score, iteration=epoch)\n",
    "            task.get_logger().report_scalar(\"Loss\", \"validation\", value=val_loss, iteration=epoch)\n",
    "\n",
    "    # Final evaluation on test set\n",
    "    test_score, test_class_scores, test_loss = evaluate(net, test_loader, device, ampbool, traintype)\n",
    "    print('Final Test Results:')\n",
    "    print(f'Test - Dice Score: {test_score:.4f}')\n",
    "    print(f'Test - Class Dice Scores: {[f\"{score:.4f}\" for score in test_class_scores]}')\n",
    "    print(f'Test Loss: {test_loss:.4f}')\n",
    "    # return train_loss, val_loss, test_loss\n",
    "\n",
    "    # 上传最佳模型\n",
    "    task.upload_artifact(\"最佳模型\", \"./checkpoints/best_model.pth\")\n",
    "    task.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abbc24f28ad0b659",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T11:27:35.650666Z",
     "start_time": "2024-09-08T11:27:35.643565Z"
    }
   },
   "outputs": [],
   "source": [
    "classes = 5\n",
    "bilinear = True\n",
    "loadstate = False\n",
    "# loadstate = True\n",
    "load = './checkpoints/Vgg19SiamConc/checkpoint_epoch12.pth'\n",
    "start_epoch = 0\n",
    "# start_epoch = 13\n",
    "epochs = 30\n",
    "batch_size = 4\n",
    "# batch_size = 1\n",
    "lr = 2e-4\n",
    "# lr = 1e-6\n",
    "scale = 1\n",
    "train = 1\n",
    "# train =0.15259598603*2\n",
    "val = 1\n",
    "test = 1\n",
    "ampbool = True\n",
    "save_checkpoint = True\n",
    "traintype = 'both'\n",
    "gradclip = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e9ed12de022451e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T11:27:36.037059Z",
     "start_time": "2024-09-08T11:27:36.030718Z"
    }
   },
   "outputs": [],
   "source": [
    "def confusionmatrix(pred,true):\n",
    "    result = np.zeros((5,5))\n",
    "    for i in range(true.shape[1]):\n",
    "        for j in range(true.shape[2]):\n",
    "            result[true[0][i][j]][pred[0][i][j]] +=1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b948416bc246378b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T11:27:36.463463Z",
     "start_time": "2024-09-08T11:27:36.443960Z"
    }
   },
   "outputs": [],
   "source": [
    "def modelconfusionmatrix(filepath,net,train_percent,val_percent):\n",
    "    device = 'cuda'\n",
    "    net.load_state_dict(torch.load(filepath, map_location=device))\n",
    "    net.to(device=device)\n",
    "    net.eval() # 评估模式\n",
    "    \n",
    "    try:\n",
    "        train = SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, 1, values =  [[.8,1.5], True, True,True], probabilities = [0,0,0,0])\n",
    "        validate = SatelliteDataset(pre_dir_val_img, pre_dir_val_mask,post_dir_val_img, post_dir_val_mask, 1, values =  [[1,1], False, False, False], probabilities = [0,0,0,0])\n",
    "        # train = SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, 1, values =  [[.8,1.5], True, True,True], probabilities = [0,0,0,0],increase = 0 ,mask_suffix = '.png',normalizemodel = 'vgg19')\n",
    "        # validate = SatelliteDataset(pre_dir_val_img, pre_dir_val_mask,post_dir_val_img, post_dir_val_mask, 1, values =  [[1,1], False, False, False], probabilities = [0,0,0,0],increase = 0,mask_suffix = '.png', normalizemodel = 'vgg19')\n",
    "    except (AssertionError, RuntimeError):\n",
    "        print('error')\n",
    "\n",
    "    loader_args = dict(batch_size=1, num_workers=1, pin_memory=True)        \n",
    "        \n",
    "    # 2. Split into train / validation partitions\n",
    "    n_train = int(len(train) * train_percent)\n",
    "    n_train_none = int(len(train) - n_train)\n",
    "    n_val = int(len(validate) * val_percent)\n",
    "    n_val_none = int(len(validate) - n_val)\n",
    "\n",
    "    train_set, train_val_none_set = random_split(train, [n_train, n_train_none], generator=torch.Generator().manual_seed(0))\n",
    "    \n",
    "    train_loader = DataLoader(train_set, shuffle=True, **loader_args)    \n",
    "\n",
    "    val_set, val_none_set = random_split(validate, [n_val, n_val_none], generator=torch.Generator().manual_seed(0))    \n",
    "\n",
    "    val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args) \n",
    "    resulttrain = torch.zeros(5,5).to(device)\n",
    "    resultval = torch.zeros(5,5).to(device)\n",
    "\n",
    "    num_val_batches = len(val_loader)\n",
    "    num_train_batches = len(train_loader)\n",
    "    confmat = ConfusionMatrix(task=\"multiclass\", num_classes=5).to(device)\n",
    "\n",
    "    with tqdm(total=num_train_batches, desc='train', unit='img') as pbar:\n",
    "        for batch in train_loader:\n",
    "            preimage, postimage, true_masks = batch['preimage'], batch['postimage'], batch['postmask']\n",
    "            # preimage, postimage, true_masks = batch['preimage'], batch['image'], batch['mask']\n",
    "            preimage = preimage.to(device=device, dtype=torch.float32)\n",
    "            postimage = postimage.to(device=device, dtype=torch.float32)\n",
    "            true_masks = true_masks.to(device=device, dtype=torch.long)\n",
    "            mask_true = F.one_hot(true_masks, 5).permute(0,3, 1, 2).float()\n",
    "            with torch.amp.autocast('cuda', enabled = True):\n",
    "                # predict the mask\n",
    "                mask_pred = net(preimage,postimage)\n",
    "                # convert to one-hot format\n",
    "                pred = F.softmax(mask_pred, dim=1).int().argmax(-3)\n",
    "                true = F.one_hot(true_masks, 5).int().permute(0, 3, 1, 2).argmax(-3)\n",
    "                resulttrain += confmat(pred,true)\n",
    "            pbar.update(postimage.shape[0])\n",
    "    print(resulttrain)\n",
    "    with tqdm(total=num_val_batches, desc='validation', unit='img') as pbar:\n",
    "        for batch in val_loader:\n",
    "            preimage, postimage, true_masks = batch['preimage'], batch['postimage'], batch['postmask']\n",
    "            preimage = preimage.to(device=device, dtype=torch.float32)\n",
    "            postimage = postimage.to(device=device, dtype=torch.float32)\n",
    "            true_masks = true_masks.to(device=device, dtype=torch.long)\n",
    "            mask_true = F.one_hot(true_masks, 5).permute(0,3, 1, 2).float()\n",
    "            with torch.cuda.amp.autocast(enabled = True):\n",
    "                # predict the mask\n",
    "                mask_pred = net(preimage,postimage)\n",
    "                # convert to one-hot format\n",
    "                pred = F.softmax(mask_pred, dim=1).int().argmax(-3)\n",
    "                true = F.one_hot(true_masks, 5).int().permute(0, 3, 1, 2).argmax(-3)\n",
    "                resultval += confmat(pred,true)\n",
    "            pbar.update(postimage.shape[0])\n",
    "    print(resultval)\n",
    "    net.train()\n",
    "\n",
    "    # Fixes a potential division by zero error\n",
    "    if num_val_batches == 0:\n",
    "        return resulttrain,resultval\n",
    "    return resulttrain,resultval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68343e76dce750c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T11:27:36.903194Z",
     "start_time": "2024-09-08T11:27:36.890981Z"
    }
   },
   "outputs": [],
   "source": [
    "def EvaluateFolder(folderpath,net,train_percent,val_percent):\n",
    "    in_files = [folderpath + s for s in os.listdir(folderpath)]\n",
    "    try:\n",
    "        train = SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, 1, values =  [[.8,1.5], True, True,True], probabilities = [0,0,0,0])\n",
    "        # train = SatelliteDataset(pre_dir_img, pre_dir_mask,post_dir_img, post_dir_mask, 1, values =  [[.8,1.5], True, True,True], probabilities = [0,0,0,0],increase = 0 ,mask_suffix = '.png',normalizemodel = 'vgg19')\n",
    "        validate = SatelliteDataset(pre_dir_val_img, pre_dir_val_mask,post_dir_val_img, post_dir_val_mask, 1, values =  [[1,1], False, False, False], probabilities = [0,0,0,0]) \n",
    "        # validate = SatelliteDataset(pre_dir_val_img, pre_dir_val_mask,post_dir_val_img, post_dir_val_mask, 1, values =  [[1,1], False, False, False], probabilities = [0,0,0,0],increase = 0,mask_suffix = '.png', normalizemodel = 'vgg19')\n",
    "    except (AssertionError, RuntimeError):\n",
    "        print('error')\n",
    "\n",
    "    loader_args = dict(batch_size=1, num_workers=1, pin_memory=True)        \n",
    "        \n",
    "    # 2. Split into train / validation partitions\n",
    "    n_train = int(len(train) * train_percent)\n",
    "    n_train_none = int(len(train) - n_train)\n",
    "    n_val = int(len(validate) * val_percent)\n",
    "    n_val_none = int(len(validate) - n_val)\n",
    "\n",
    "    train_set, train_val_none_set = random_split(train, [n_train, n_train_none], generator=torch.Generator().manual_seed(0))\n",
    "    \n",
    "    train_loader = DataLoader(train_set, shuffle=True, **loader_args)    \n",
    "\n",
    "    val_set, val_none_set = random_split(validate, [n_val, n_val_none], generator=torch.Generator().manual_seed(0))    \n",
    "\n",
    "    val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    loader_args = dict(batch_size=1, num_workers=1, pin_memory=True)        \n",
    "    \n",
    "    for i in in_files:\n",
    "        net.load_state_dict(torch.load(i, map_location=device))\n",
    "        net.to(device=device)\n",
    "        val_score, val_classes,val_loss = evaluate(net,dataloader = val_loader,device = device,ampbool = True,traintype = 'both')\n",
    "        train_score, train_classes,train_loss = evaluate(net,dataloader = train_loader,device = device,ampbool = True,traintype = 'both')\n",
    "        print('Train: ' + i)\n",
    "        print(train_score)\n",
    "        print(train_classes)\n",
    "        print(train_loss)\n",
    "        print('Validation: ' + i)\n",
    "        print(val_score)\n",
    "        print(val_classes)\n",
    "        print(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96d2349ef657b1a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T11:27:40.659909Z",
     "start_time": "2024-09-08T11:27:38.064221Z"
    }
   },
   "outputs": [],
   "source": [
    "# net = SiamUNetConCVgg19()\n",
    "net = SiameseUNetWithResnet50Encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6693f5575c23882e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T11:27:41.944068Z",
     "start_time": "2024-09-08T11:27:40.676926Z"
    }
   },
   "outputs": [],
   "source": [
    "# EvaluateFolder('./checkpoints/Final/',net,train,val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65f38a4fc06055b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T11:27:44.002548Z",
     "start_time": "2024-09-08T11:27:43.992655Z"
    }
   },
   "outputs": [],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, net.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc9435c0dde00a3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-08T11:27:45.033331Z",
     "start_time": "2024-09-08T11:27:45.020497Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "553700636"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_params = sum([param.nelement()*param.element_size() for param in net.parameters()])\n",
    "mem_bufs = sum([buf.nelement()*buf.element_size() for buf in net.buffers()])\n",
    "mem = mem_params + mem_bufs\n",
    "mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71f391e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CLEARML_WEB_HOST=https://app.clear.ml/\n",
      "env: CLEARML_API_HOST=https://api.clear.ml\n",
      "env: CLEARML_FILES_HOST=https://files.clear.ml\n",
      "env: CLEARML_API_ACCESS_KEY=I1U0VQJD2RGIMV51MGC2XZGUUJKSS5\n",
      "env: CLEARML_API_SECRET_KEY=E3YMSWc-e6i8FBMpnvnpNJAKJBMztVtbc7z2xtEzG8Sj6v3y3HR3QUQ-genJV-UUlWU\n"
     ]
    }
   ],
   "source": [
    "%env CLEARML_WEB_HOST=https://app.clear.ml/\n",
    "%env CLEARML_API_HOST=https://api.clear.ml\n",
    "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
    "%env CLEARML_API_ACCESS_KEY=I1U0VQJD2RGIMV51MGC2XZGUUJKSS5\n",
    "%env CLEARML_API_SECRET_KEY=E3YMSWc-e6i8FBMpnvnpNJAKJBMztVtbc7z2xtEzG8Sj6v3y3HR3QUQ-genJV-UUlWU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1fb80075cdc127b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-09-08T11:27:45.919734Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClearML Task: created new task id=a710a89d843c424ba02b0fa1e43437dd\n",
      "2024-09-15 00:59:44,642 - clearml.Task - INFO - Storing jupyter notebook directly as code\n",
      "ClearML results page: https://app.clear.ml/projects/1d1f3e0402f040a0af215c903b06950c/experiments/a710a89d843c424ba02b0fa1e43437dd/output/log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0/30:   0%|          | 14/2800 [00:52<2:52:48,  3.72s/img, accuracy=0.0294, loss=2.64, loss (batch)=2.56, precision=0.2, recall=0.148] "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # # 初始化 ClearML Task\n",
    "    # task = Task.init(project_name=\"damage-assessment\", \n",
    "    #                  task_name=\"train SiameseUNetWithResnet50Encoder\")\n",
    "    task_id_to_resume = \"432ff2e399124e32977edbeb13c7e30a\"  # 替换为您想恢复的任务 ID\n",
    "\n",
    "    # 初始化 ClearML Task\n",
    "    task = Task.get_task(task_id=task_id_to_resume)\n",
    "    task.mark_started(force=True)\n",
    "    # 记录超参数\n",
    "    task.connect({\n",
    "        \"batch_size\": batch_size,\n",
    "        \"learning_rate\": lr,\n",
    "        \"epochs\": epochs,\n",
    "        \"img_scale\": scale,\n",
    "        \"train_percent\": train,\n",
    "        \"val_percent\": val,\n",
    "        \"ampbool\": ampbool,\n",
    "        \"traintype\": traintype,\n",
    "        \"gradient_clipping\": gradclip\n",
    "    })\n",
    "\n",
    "    # 记录超参数\n",
    "    task.connect({\n",
    "        \"batch_size\": batch_size,\n",
    "        \"learning_rate\": lr,\n",
    "        \"epochs\": epochs,\n",
    "        \"img_scale\": scale,\n",
    "        \"train_percent\": train,\n",
    "        \"val_percent\": val,\n",
    "        \"ampbool\": ampbool,\n",
    "        \"traintype\": traintype,\n",
    "        \"gradient_clipping\": gradclip\n",
    "    })\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "    #net = SiamUNetDiff()\n",
    "    #net = SiamUNetConC()\n",
    "    #net = SiameseUNetWithResnet50Encoder()\n",
    "    #net = SiamUnet_diff_Full(3,5)\n",
    "    #net = UNetWithResnet50Encoder(5,'custom','./checkpoints/Resnet50ContrastiveWeight/checkpoint_epoch0.pth')\n",
    "    #net = UNet(out_classes=classes, up_sample_mode='conv_transpose',batch_norm=False)\n",
    "    #net = SiameseUNet(n_channels=3, n_classes = classes, bilinear=bilinear)\n",
    "    #net = UNetVgg19V2(out_classes=classes, up_sample_mode='conv_transpose')\n",
    "    #net = vgg19bn_unet(5,True)\n",
    "    #net = vgg19nobn_unet(5,True)\n",
    "    #net = vgg19nobn_unetdouble(5,True)\n",
    "    #net = VGGUnet19nobnspace(out_channels = 5, pretrained = True)\n",
    "    #net = SiamUNetCombVgg19()\n",
    "    ### 之前是用这个 net = SiamUNetConCVgg19()\n",
    "    #net = resnet_unet()\n",
    "    #net = VGG16Unet(out_channels = 5)\n",
    "    #net = resnet_siamunet()\n",
    "    #net = SiamUNetDiffVgg19()\n",
    "    #net = SiamUNetFullConCVgg19()\n",
    "    #net = SiamUNetConCResnet50(True,5)\n",
    "    #net = UNETResnet50(True,2)\n",
    "    '''net = smp.Unet(\n",
    "        encoder_name='resnext101_32x8d',\n",
    "        encoder_depth=5,\n",
    "        encoder_weights='imagenet',\n",
    "        decoder_use_batchnorm=False,\n",
    "        decoder_channels=(1024,512,256,128, 64),\n",
    "        decoder_attention_type=None,\n",
    "        in_channels=3,\n",
    "        classes=5,\n",
    "        activation=None,\n",
    "        aux_params=None\n",
    "    )\n",
    "    '''\n",
    "    if loadstate:\n",
    "        net.load_state_dict(torch.load(load, map_location=device))\n",
    "        logging.info(f'Model loaded from {load}')\n",
    "\n",
    "    net.to(device=device)\n",
    "\n",
    "    train_net(net=net,\n",
    "                  start_epoch = start_epoch,\n",
    "                  epochs=epochs,\n",
    "                  batch_size=batch_size,\n",
    "                  learning_rate=lr,\n",
    "                  device=device,\n",
    "                  img_scale=scale,\n",
    "                  train_percent = train,\n",
    "                  val_percent=val,\n",
    "                  save_checkpoint = save_checkpoint,\n",
    "                  ampbool = ampbool,\n",
    "                  traintype = traintype,\n",
    "                  gradient_clipping=gradclip)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
